{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importación de librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, re\n",
    "from gensim.parsing.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__paths to change__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input variables\n",
    "documents_path = './datos/docs-raw-texts/'\n",
    "queries_path = './datos/queries-raw-texts/'\n",
    "output_path = './salida/'\n",
    "relevance_judgements_path = 'relevance-judgments.tsv'\n",
    "results_file_path = './salida/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read documents methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_documents(path: str) -> list:\n",
    "    \"\"\"\n",
    "    read raw text from naf documents located in the directory path\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    for file in sorted(os.listdir(path)):\n",
    "        if file.endswith(\".naf\"):\n",
    "            tree = ET.parse(path + file)\n",
    "            text = tree.find('raw').text\n",
    "            header = tree.find('nafHeader')\n",
    "            if header:\n",
    "                desc = header.find('fileDesc')\n",
    "                if desc:\n",
    "                    title = desc.attrib.get('title')\n",
    "                    text = title + ' ' + text if title else text\n",
    "            data.append(text)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(document: str) -> list:\n",
    "    \"\"\"\n",
    "    remove the english stop words from data\n",
    "    \"\"\"\n",
    "    lower = document.lower()\n",
    "    words = lower.split(' ')\n",
    "    stop_words = stopwords.words('english')\n",
    "    return [word for word in words if word not in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_nonlatin(document: str) -> str:\n",
    "    \"\"\"\n",
    "    replace problematic characters\n",
    "    \"\"\"\n",
    "    document = re.sub('\\n', ' ', document)\n",
    "    document = re.sub('[^a-zA-Z]|[0-9]', ' ', document)\n",
    "    document = re.sub('\\s+', ' ', document)\n",
    "    return document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(document: str) -> list:\n",
    "    \"\"\"\n",
    "    clean data by removing non-latin characters\n",
    "    stem data sentences\n",
    "    remove stop words from a document\n",
    "    \"\"\"\n",
    "    porter = PorterStemmer()\n",
    "    document = remove_nonlatin(document)\n",
    "    document = porter.stem_sentence(document)\n",
    "    document = remove_stopwords(document)\n",
    "    return document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### indexes and doc-term matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_words_index(documents: pd.Series) -> pd.Index:\n",
    "    \"\"\"\n",
    "    return a sorted index of every word in the texts\n",
    "    \"\"\"\n",
    "    # get all words in all documents\n",
    "    words = set()\n",
    "    for document in documents:\n",
    "        words.update(set(document))\n",
    "    # sort the words\n",
    "    sorted_words = sorted(list(words))\n",
    "    # get index of sorted words\n",
    "    words_frame = pd.DataFrame(sorted_words, columns=['data'])\n",
    "    words_index = words_frame.set_index('data').index\n",
    "    return words_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_index_word(word: str, words_index: pd.Index) -> int:\n",
    "    \"\"\"\n",
    "    return the provided word index\n",
    "    \"\"\"\n",
    "    try: return words_index.get_loc(word)\n",
    "    except: return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_doc_term(documents: pd.DataFrame, words_index: pd.Index) -> list:\n",
    "    \"\"\"\n",
    "    return the document term matrix that indicate how many terms repeats in each document\n",
    "    \"\"\"\n",
    "    doc_term = [[0]*len(documents) for _ in range(len(words_index))]\n",
    "    for doc_index, document in documents.iterrows():\n",
    "        for word in document.filtered:\n",
    "            word_index = get_index_word(word, words_index)\n",
    "            if word_index != -1:\n",
    "                doc_term[word_index][doc_index] += 1\n",
    "    return doc_term"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Representación vectorial ponderada tf.idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tf(doc_term: list) -> list:\n",
    "    \"\"\"\n",
    "    return the ft score from each word in all the documents\n",
    "    \"\"\"\n",
    "    return [[1 + np.log10(doc) if doc > 0 else 0 for doc in word] for word in doc_term]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_idf(doc_term: list) -> list:\n",
    "    \"\"\"\n",
    "    return the idf score from each word in the entire collection\n",
    "    \"\"\"\n",
    "    word_num = len(doc_term)\n",
    "    return [np.log10(word_num/sum([1 if doc > 0 else 0 for doc in word])) for word in doc_term]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tfidf(doc_term: list) -> list:\n",
    "    \"\"\"\n",
    "    ponderate the tf-idf scores multiping them\n",
    "    \"\"\"\n",
    "    tf = get_tf(doc_term)\n",
    "    idf = get_idf(doc_term)\n",
    "    return [[tf_scr * idf[i] for tf_scr in words] for i, words in enumerate(tf)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_term = [\n",
    "    [157, 73, 0, 0, 0, 0],\n",
    "    [4, 157, 0, 1, 0, 0],\n",
    "    [232, 227, 0, 2, 1, 1],\n",
    "    [0, 1, 0, 0, 0, 0, 0],\n",
    "    [57, 0, 0, 0, 0, 0],\n",
    "    [2, 0, 3, 5, 5, 1],\n",
    "    [2, 0, 1, 1, 1, 0]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = get_tfidf(doc_term)\n",
    "tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: get documents\n",
    "data = get_documents(documents_path)\n",
    "documents = pd.DataFrame(data, columns=['data'])\n",
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: apply the preprocessing method\n",
    "documents['filtered'] = documents.data.apply(preprocessing)\n",
    "documents.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: get word-index, doc-term, and the tfidf index\n",
    "words_index = get_words_index(documents.filtered)\n",
    "doc_term = get_doc_term(documents, words_index)\n",
    "tfidf = get_tfidf(doc_term)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## similitud del coseno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similitud_coseno(vector1:list,vector2:list) -> float:\n",
    "    \"\"\"\n",
    "    Calcula la similitud entre dos vectores de documentos de acuerdo al ángulo entre estos\n",
    "    haciendo uso de la función coseno\n",
    "\n",
    "    Se hace uso de las funciones de numpy para poder calcular el coseno entre dos vectores,\n",
    "    que por definición es el producto punto entre el vector1 y el vector2, dividido entre el \n",
    "    producto de las normas de ambos vectores\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    vector1 : list\n",
    "        vector del primer documento a comparar\n",
    "    vector2 : list\n",
    "        vector del segundo documento a comparar\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        La similitud coseno entre vector1 y vector2\n",
    "    \"\"\"\n",
    "    producto_punto = np.dot(vector1,vector2)\n",
    "    norma_1 = np.linalg.norm(vector1)\n",
    "    norma_2 = np.linalg.norm(vector2)\n",
    "    return producto_punto/(norma_1*norma_2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Procesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Se leen los documentos, se cargan en un dataFrame, se preprocesan para obtener los\n",
    "tokens del corpus de los documentos.\n",
    "\"\"\"\n",
    "datos = get_documents(documents_path)\n",
    "documentos = pd.DataFrame(datos,columns=['Documento'])\n",
    "documentos['filtrada']=documentos['Documento'].apply(preprocessing)\n",
    "doc_proc= documentos\n",
    "doc_proc.filtrada = doc_proc.filtrada.apply(np.unique)\n",
    "doc_proc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Se crea un diccionario a partir de los tokens obtenidos en todos\n",
    "los documentos cargados anteriormente, donde la llave es el token \n",
    "y el valor es un id del token.\n",
    "\"\"\"\n",
    "dictionary = {}\n",
    "for i in range(len(doc_proc)):\n",
    "    for j in range(len(doc_proc.iloc[i]['filtrada'])):\n",
    "        if doc_proc.iloc[i]['filtrada'][j] not in dictionary:\n",
    "            dictionary[doc_proc.iloc[i]['filtrada'][j]] = len(dictionary)\n",
    "dictionary_size = len(dictionary)\n",
    "dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doc_to_vector(doc):\n",
    "    \"\"\"\n",
    "    Transforma un documento a un vector binario de acuerdo al \n",
    "    diccionario generado a partir del conjunto total de documentos\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    doc : list\n",
    "        vector de tokens del documento a convertir a vector binario\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        documento como vector binario\n",
    "    \"\"\"\n",
    "\n",
    "    vector = np.zeros(dictionary_size)\n",
    "    for token in doc:\n",
    "        if token in dictionary:\n",
    "            vector[dictionary[token]] = 1\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "A partir del diccionario de palabras generado se convierte el documento a \n",
    "vector\n",
    "\"\"\"\n",
    "doc_proc['doc_vector'] = doc_proc.filtrada.apply(doc_to_vector)\n",
    "doc_proc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Se leen y se cargan las queries en dataframes \n",
    "\"\"\"\n",
    "datos_querry = get_documents(queries_path)\n",
    "queries = pd.DataFrame(datos_querry,columns=['Query'])\n",
    "queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Se preprocessan las queries cargadas para obtener los tokens de estas\n",
    "\"\"\"\n",
    "queries['filtrada'] = queries.Query.apply(preprocessing)\n",
    "quer_proc = queries\n",
    "quer_proc.filtrada = quer_proc.filtrada.apply(np.unique)\n",
    "quer_proc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Se convierten las queries a vectores\n",
    "\"\"\"\n",
    "quer_proc['query_vector'] = quer_proc.filtrada.apply(doc_to_vector)\n",
    "quer_proc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similitud_coseno_docs(query_vector:list) -> str:\n",
    "    \"\"\"\n",
    "    Calcula la similitud coseno para cada uno de los documentos con respecto\n",
    "    a una query realizada. A partir de los resultados obtenidos, elimina los\n",
    "    que sean igual a 0, se ordenan descendentement y se genera el string \n",
    "    resultante en el formato especificado para el output de RRDV\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    query_vector : list\n",
    "        documento como vector de la query respectiva\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    str \n",
    "        string resultante en el formato especificado para el output de RRDV con\n",
    "        los documentos recuperados clasficados - ordenados por el puntaje de \n",
    "        similitud del coseno.\n",
    "    \"\"\"\n",
    "\n",
    "    similitud = doc_proc['doc_vector'].apply(lambda x: similitud_coseno(x,query_vector))\n",
    "    similitud = similitud[similitud>0]\n",
    "    similitud = similitud.sort_values(ascending=False)\n",
    "    output = ''\n",
    "    for index, value in similitud.items():\n",
    "        if output == '':\n",
    "            output += f'd{index}:{value}'\n",
    "        else:\n",
    "            output += f',d{index}:{value}'\n",
    "    return output\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Se le aplica la funcion de similitud coseno a cada una de las queries \n",
    "sobre todos los documentos. El resultado es escrito en el archivo de\n",
    "salida\n",
    "\"\"\"\n",
    "q = quer_proc.query_vector.apply(similitud_coseno_docs)\n",
    "f = open(output_path+\"RRDV-consultas_resultados.txt\", \"w\")\n",
    "for i in range(len(q)):\n",
    "    f.write(f'q{i+1} {q[i]}\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluación de resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usando las funciones descritas en `metricas.ipynb`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_at_k(relevance_query: list, k: int) -> float:\n",
    "    if k > 0 and k <= len(relevance_query):\n",
    "        return sum(relevance_query[:k]) / k\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def recall_at_k(relevance_query: list, number_relevant_docs:int, k: int) -> float:\n",
    "    if k > 0 and k <= len(relevance_query):\n",
    "        return sum(relevance_query[:k]) / number_relevant_docs\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def average_precision(relevance_query:list) -> float :\n",
    "    relevant_docs = np.sum(relevance_query)\n",
    "    last_recall = 0\n",
    "    precisions = np.array([])\n",
    "    for i in range(1,len(relevance_query)+1):\n",
    "        recall = recall_at_k(relevance_query,relevant_docs,i)\n",
    "        if recall > last_recall:\n",
    "            last_recall = recall \n",
    "            precisions= np.append(precisions,precision_at_k(relevance_query,i))\n",
    "    return np.average(precisions)\n",
    "\n",
    "def mean_average_precision(list_vectors: list)-> float:\n",
    "    average_precisions = list(map(average_precision, list_vectors))\n",
    "    return np.average(average_precisions)\n",
    "\n",
    "def dcg_at_k(rel, k):\n",
    "    import math\n",
    "    result = 0\n",
    "    for i in range(k):\n",
    "        discount_factor = 1/math.log(max([i+1, 2]), 2)\n",
    "        gain = + (rel[i]*discount_factor)\n",
    "        result = result + gain \n",
    "    return result\n",
    "    \n",
    "def ndcg_at_k(rel, k):\n",
    "    DCG = dcg_at_k(rel, k)\n",
    "    IDCG = dcg_at_k(sorted(rel, reverse=True), k)\n",
    "    result = DCG/IDCG\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relevance_judgements(path: str) -> list:\n",
    "    \"\"\"\n",
    "    Transforma el documento de juicios de relevancia a una lista de diccionarios por consulta\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    path : str\n",
    "        Ubicación del archivo (incluyendo nombre del archivo)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        Lista de diccionarios, un diccionario representa los documentos relevantes para una consulta\n",
    "    \"\"\"\n",
    "    relevance_dicts = []\n",
    "    for line in open(path, \"r\"):\n",
    "        line_proc = line.split(\"\\n\")[0]\n",
    "        docs_str = line_proc.split(\"\\t\")[1]\n",
    "        docs_list = docs_str.split(\",\")\n",
    "        current_relevance_dict = {}\n",
    "        for doc in docs_list:\n",
    "            doc_split = doc.split(\":\")\n",
    "            doc_id = doc_split[0].split(\"d\")[1]\n",
    "            doc_relevance = doc_split[1]\n",
    "            current_relevance_dict[doc_id] = doc_relevance\n",
    "        relevance_dicts.append(current_relevance_dict)\n",
    "    return relevance_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_result_relevances(path: str, relevance_lists: list) -> list:\n",
    "    \"\"\"\n",
    "    Retorna una lista donde los resultados de cada consulta se representan como una lista\n",
    "    con la relevancia entera.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    path : str\n",
    "        Ubicación del archivo de resultados (incluyendo nombre del archivo)\n",
    "    relevance_lists : list\n",
    "        Lista de diccionarios obtenida con la función get_relevance_judgements()\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        Lista de listas, cada lista representa los resultados para una consulta con relevancia entera\n",
    "    \"\"\"\n",
    "    res = []\n",
    "    for i, line in enumerate(open(path, \"r\")):\n",
    "        line_proc = line.split(\"\\n\")[0]\n",
    "        if len(line_proc.split(\"\\t\")) == 0:\n",
    "            docs_str = line_proc.split(\"\\t\")[1]\n",
    "        else:\n",
    "            docs_str = line_proc.split(\" \")[1]\n",
    "        docs_list = docs_str.split(\",\")\n",
    "        current_relevance_list = []\n",
    "        for doc in docs_list:\n",
    "            doc_split = doc.split(\":\")\n",
    "            doc_id = doc_split[0].split(\"d\")[1]\n",
    "            if doc_id in relevance_lists[i]:\n",
    "                current_relevance_list.append(int(relevance_lists[i][doc_id]))\n",
    "            else:\n",
    "                current_relevance_list.append(0)\n",
    "        res.append(current_relevance_list)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_binary_result_relevances(path: str, relevance_lists: list) -> list:\n",
    "    \"\"\"\n",
    "    Retorna una lista donde los resultados de cada consulta se representan como una lista\n",
    "    con la relevancia binaria.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    path : str\n",
    "        Ubicación del archivo de resultados (incluyendo nombre del archivo)\n",
    "    relevance_lists : list\n",
    "        Lista de diccionarios obtenida con la función get_relevance_judgements()\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        Lista de listas, cada lista representa los resultados para una consulta con relevancia binaria\n",
    "    \"\"\"\n",
    "    res = []\n",
    "    for i, line in enumerate(open(path, \"r\")):\n",
    "        line_proc = line.split(\"\\n\")[0]\n",
    "        if len(line_proc.split(\"\\t\")) == 0:\n",
    "            docs_str = line_proc.split(\"\\t\")[1]\n",
    "        else:\n",
    "            docs_str = line_proc.split(\" \")[1]\n",
    "        docs_list = docs_str.split(\",\")\n",
    "        current_relevance_list = []\n",
    "        if docs_list[0] != '':\n",
    "            for doc in docs_list:\n",
    "                doc_split = doc.split(\":\")\n",
    "                doc_id = doc_split[0].split(\"d\")[1]\n",
    "                if doc_id in relevance_lists[i]:\n",
    "                    current_relevance_list.append(1)\n",
    "                else:\n",
    "                    current_relevance_list.append(0)\n",
    "        res.append(current_relevance_list)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_list(binary_result_relevances: list, relevance_lists: list) -> list:\n",
    "    \"\"\"\n",
    "    Retorna una lista con el valor de P@M para cada consulta.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    binary_result_relevances : list\n",
    "        Lista de relevancias binarias para cada consulta\n",
    "    relevance_lists : list\n",
    "        Lista de diccionarios obtenida con la función get_relevance_judgements()\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        Lista de float con los valores de P@M por consulta\n",
    "    \"\"\"\n",
    "    p_list = []\n",
    "    for i, query in enumerate(binary_result_relevances):\n",
    "        p_list.append(precision_at_k(query,len(relevance_lists[i])))\n",
    "    return p_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall_list(binary_result_relevances: list, relevance_lists: list) -> list:\n",
    "    \"\"\"\n",
    "    Retorna una lista con el valor de R@M para cada consulta.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    binary_result_relevances : list\n",
    "        Lista de relevancias binarias para cada consulta\n",
    "    relevance_lists : list\n",
    "        Lista de diccionarios obtenida con la función get_relevance_judgements()\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        Lista de float con los valores de R@M por consulta\n",
    "    \"\"\"\n",
    "    r_list = []\n",
    "    for i, query in enumerate(binary_result_relevances):\n",
    "        r_list.append(recall_at_k(query,len(relevance_lists[i]),len(relevance_lists[i])))\n",
    "    return r_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ndcg_list(result_relevances: list, relevance_lists: list) -> list:\n",
    "    \"\"\"\n",
    "    Retorna una lista con el valor de NDCG@M para cada consulta.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    result_relevances : list\n",
    "        Lista de relevancias enteras para cada consulta\n",
    "    relevance_lists : list\n",
    "        Lista de diccionarios obtenida con la función get_relevance_judgements()\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        Lista de float con los valores de NDCG@M por consulta\n",
    "    \"\"\"\n",
    "    ndcg_l = []\n",
    "    for i, query in enumerate(result_relevances):\n",
    "        ndcg_l.append(ndcg_at_k(query,len(relevance_lists[i])))\n",
    "    return ndcg_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Se obtienen los juicios de relevancia desde el archivo\n",
    "\"\"\"\n",
    "relevance_dicts = get_relevance_judgements(relevance_judgements_path)\n",
    "relevance_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Se obtiene la lista de relevancias binarias para las consultas\n",
    "\"\"\"\n",
    "binary_result_relevances = get_binary_result_relevances(output_path+\"RRDV-consultas_resultados.txt\", relevance_dicts)\n",
    "binary_result_relevances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Se obtiene la lista de relevancias enteras para las consultas\n",
    "\"\"\"\n",
    "result_relevances = get_result_relevances(output_path+\"RRDV-consultas_resultados.txt\", relevance_dicts)\n",
    "result_relevances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Se calculan las métricas para todas las consultas. El resultado es escrito en el archivo de\n",
    "salida para métricas\n",
    "\"\"\"\n",
    "precision = precision_list(binary_result_relevances, relevance_dicts)\n",
    "recall = recall_list(binary_result_relevances, relevance_dicts)\n",
    "ndcg = ndcg_list(result_relevances, relevance_dicts)\n",
    "f = open(output_path+\"RRDV-metricas.txt\", \"w\")\n",
    "for i in range(len(precision)):\n",
    "    f.write(f'q{i+1} P@M:{precision[i]}, R@M:{recall[i]}, NDCG@M:{ndcg[i]}\\n')\n",
    "f.write(f'\\nMAP:{mean_average_precision(binary_result_relevances)}')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "c7a79e9e75522a046d95171e373010a5dca4ce6e8605d007854b2218f1d88052"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
