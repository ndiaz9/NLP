{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7710d98-5abf-4dfa-8c7b-9bbde6a4f59c",
   "metadata": {},
   "source": [
    "### BSII"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c1af16-0c01-48ae-a0be-ed8e560c2ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, re, json\n",
    "from gensim.parsing.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5175e17-3ab1-442e-94b3-8db1c61007df",
   "metadata": {},
   "source": [
    "__paths to change__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3619551e-8ab1-4e4b-b0fb-102e5ae5d4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input variables\n",
    "documents_path = './input/docs-raw-texts/'\n",
    "queries_path = './input/queries-raw-texts/'\n",
    "\n",
    "# output varibles\n",
    "inverted_index_path = './output/inverted_index.json'\n",
    "bsii_and_path = './output/BSII-AND-queries_results.txt'\n",
    "bsii_or_path = './output/BSII-OR-queries_results.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce7ae30-5efc-4708-ab54-0e3163efee38",
   "metadata": {},
   "source": [
    "### Read documents methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f5fd57-ebf1-4dab-bd55-30f1bf61d648",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_documents(path: str) -> list:\n",
    "    \"\"\"\n",
    "    read raw text from naf documents located in the directory path\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    for file in sorted(os.listdir(path)):\n",
    "        if file.endswith(\".naf\"):\n",
    "            tree = ET.parse(path + file)\n",
    "            text = tree.find('raw').text\n",
    "            header = tree.find('nafHeader')\n",
    "            if header:\n",
    "                desc = header.find('fileDesc')\n",
    "                if desc:\n",
    "                    title = desc.attrib.get('title')\n",
    "                    text = title + ' ' + text if title else text\n",
    "            data.append(text)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ebe2f4-aa04-498e-a146-46de8b0ad943",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(document: str) -> list:\n",
    "    \"\"\"\n",
    "    remove the english stop words from data\n",
    "    \"\"\"\n",
    "    lower = document.lower()\n",
    "    words = lower.split(' ')\n",
    "    stop_words = stopwords.words('english')\n",
    "    return [word for word in words if word not in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ca268d-ad57-4023-9a60-461decd7a825",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_nonlatin(document: str) -> str:\n",
    "    \"\"\"\n",
    "    replace problematic characters\n",
    "    \"\"\"\n",
    "    document = re.sub('\\n', ' ', document)\n",
    "    document = re.sub('[^a-zA-Z]|[0-9]', ' ', document)\n",
    "    document = re.sub('\\s+', ' ', document)\n",
    "    return document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09180d00-12f9-440c-90c0-52892c99e9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(document: str) -> list:\n",
    "    \"\"\"\n",
    "    clean data by removing non-latin characters or numbers\n",
    "    stem data sentences\n",
    "    remove stop words from a document\n",
    "    \"\"\"\n",
    "    porter = PorterStemmer()\n",
    "    document = remove_nonlatin(document)\n",
    "    document = porter.stem_sentence(document)\n",
    "    return remove_stopwords(document)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de04ed7-da90-4134-92ad-c7c79472f82b",
   "metadata": {},
   "source": [
    "### Inverted index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f553b57c-22b3-4986-a064-f40d1366e5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inverted_index(documents: pd.Series) -> dict:\n",
    "    \"\"\"\n",
    "    iterate over the words in all the documents and add their index in a dictionary\n",
    "    \"\"\"\n",
    "    inverted_index = {}\n",
    "    for i in range(len(documents)):\n",
    "        for j in range(len(documents.iloc[i])):\n",
    "            word = documents.iloc[i][j]\n",
    "            if word not in inverted_index:\n",
    "                inverted_index[word] = []\n",
    "            inverted_index[word].append(i+1)\n",
    "    return inverted_index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106ebbf7-f9b3-4f58-8548-a40b75b7e03a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### AND/OR Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ddd4b3b-4b7d-4ca7-a5af-b11c2d896fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def BSII_AND(query: list) -> str:\n",
    "    \"\"\"\n",
    "    iterate over all words in the query\n",
    "    with each word retrieve all documents where is presented\n",
    "    comparing with the next word's retrieve documents\n",
    "    \"\"\"\n",
    "    a_list = inverted_index.get(query[0])\n",
    "    if len(a_list) > 0: \n",
    "        for i in range(1, len(query)):\n",
    "            b_list = inverted_index.get(query[i])\n",
    "            if not b_list: \n",
    "                a_list = []\n",
    "                break\n",
    "            a_list = and_merge_algorihtm(a_list, b_list)\n",
    "    return ','.join([f'd{x:03}' for x in a_list]) if len(a_list) > 0 else ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d8168d-4831-43ce-93de-1a4dcef68dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def and_merge_algorihtm(l1: list, l2: list) -> list:\n",
    "    \"\"\"\n",
    "    and implementatin for merge algorithm\n",
    "    \"\"\"\n",
    "    answer = []\n",
    "    i1, i2 = 0, 0\n",
    "    len_l1, len_l2 = len(l1), len(l2)\n",
    "    while i1 < len_l1 and i2 < len_l2:\n",
    "        val1, val2 = l1[i1], l2[i2]\n",
    "        if val1 == val2:\n",
    "            answer.append(val1)\n",
    "            i1 += 1\n",
    "            i2 += 1\n",
    "        elif val1 < val2:\n",
    "            i1 += 1\n",
    "        else:\n",
    "            i2 += 1\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea78310-e2f4-4633-8b43-9cce73c612c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def BSII_OR(query: list) -> str:\n",
    "    \"\"\"\n",
    "    iterate over all query's words\n",
    "    searching each one in the inverted index dictionary\n",
    "    removing the repeating items\n",
    "    \"\"\"\n",
    "    a_list = inverted_index.get(query[0])\n",
    "    if len(a_list) == 0: \n",
    "        a_list = []\n",
    "    for i in range(1, len(query)):\n",
    "        b_list = inverted_index.get(query[i])\n",
    "        if not b_list: \n",
    "            b_list = []\n",
    "        a_list = a_list + b_list\n",
    "    a_list = np.unique(a_list)\n",
    "    return ','.join([f'd{x:03}' for x in a_list]) if len(a_list) > 0 else ''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff79ba3",
   "metadata": {},
   "source": [
    "### NOT Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80cb74fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def BSII_NOT(query):\n",
    "    \"\"\"\n",
    "    iterate over all query's words\n",
    "    searching each one in the inverted index dictionary\n",
    "    removing the repeating items\n",
    "    \"\"\"\n",
    "    all_list= list(range(1,332))\n",
    "    if len(query) == 0:\n",
    "        return ','.join([f'd{x:03}' for x in all_list])\n",
    "    if len(query) == 1:\n",
    "        a_list = inverted_index[query[0]]\n",
    "        for elem in a_list:\n",
    "            all_list.remove(elem)\n",
    "        return ','.join([f'd{x:03}' for x in all_list])\n",
    "    else:\n",
    "        a_list = inverted_index[query[0]].copy()\n",
    "        for i in range(1,len(query)):\n",
    "            if query[i] in inverted_index:\n",
    "                b_list = inverted_index[query[i]]\n",
    "                c_list =  a_list.copy()+b_list.copy()\n",
    "                a_list = c_list.copy()\n",
    "\n",
    "        a_list = np.unique(a_list)  \n",
    "        \n",
    "        for elem in a_list:\n",
    "            all_list.remove(elem)\n",
    "        return ','.join([f'd{x:03}' for x in all_list])     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06c19c0-8b66-4df1-a6bc-bb4d6c2b3ee9",
   "metadata": {},
   "source": [
    "### Process the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7117799f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: get documents\n",
    "data = get_documents(documents_path)\n",
    "documents = pd.DataFrame(data, columns=['data'])\n",
    "documents.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7abe327c-3cba-43fa-9bc1-eaff96f5561a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: apply the preprocessing function\n",
    "documents['filtered'] = documents.data.apply(preprocessing)\n",
    "documents.filtered = documents.filtered.apply(np.unique)\n",
    "documents.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a86662",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7637ff-52c7-4454-b425-dc25c909a68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: get inverted index\n",
    "inverted_index = get_inverted_index(documents.filtered)\n",
    "len(inverted_index['also'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf038ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save json file with inverted index\n",
    "with open(inverted_index_path, \"w\") as file:\n",
    "    json.dump(inverted_index, file)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9600b375-8485-4e20-a4f2-633e779763c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open json file with inverted index\n",
    "with open(inverted_index_path, \"r\") as file:\n",
    "    json_file = file.read()\n",
    "    inverted_index = json.loads(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc1a1c8-ee3b-4a86-a963-9ccd1651bfd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_query = get_documents(queries_path)\n",
    "queries = pd.DataFrame(data_query, columns=['data'])\n",
    "queries.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6bc91c-dc65-4091-9ca2-ddef858ae3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "queries['filtered'] = queries.data.apply(preprocessing)\n",
    "queries.filtered = queries.filtered.apply(np.unique)\n",
    "queries.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a745e7a2-cd20-488e-b8c2-7decb5994ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_and=queries.filtered.apply(BSII_AND)\n",
    "print(q_and)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41afd78-c33d-4fed-8a01-236920fc2586",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(bsii_and_path, \"w\") as f:\n",
    "    for i in range(len(q_and)):\n",
    "        f.write(f'q{i+1:02} {q_and[i]}\\n')\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce715a8d-68f8-4bf5-a50f-26aba384b75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_or=queries.filtered.apply(BSII_OR)\n",
    "print(q_or)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49a409a-645e-4d48-b709-d39e8606ae12",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(bsii_or_path, \"w\") as f:\n",
    "    for i in range(len(q_or)):\n",
    "        f.write(f'q{i+1:02} {q_or[i]}\\n')\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2ebd6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "q_not=queries.filtrada.apply(BSII_NOT)\n",
    "print(q_not)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98426736",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "f = open(\"salida/BSII-NOT-queries_results.txt\", \"w\")\n",
    "for i in range(len(q_not)):\n",
    "    f.write(f'q{i+1:02} {q_not[i]}\\n')\n",
    "f.close() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
