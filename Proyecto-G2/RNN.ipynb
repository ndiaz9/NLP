{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Redes Recurrentes**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libreries\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datasets \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import keras \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# -- Keras Import\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.preprocessing import image\n",
    "\n",
    "from keras.datasets import imdb\n",
    "from keras.datasets import mnist\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing import sequence\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import LSTM, GRU, SimpleRNN\n",
    "\n",
    "from keras.layers import Activation, TimeDistributed, RepeatVector\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "from keras.layers import TextVectorization\n",
    "from gensim.parsing.porter import PorterStemmer \n",
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "import re\n",
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 20000\n",
    "maxlen = 100  # cut texts after this number of words (among top max_features most common words)\n",
    "batch_size = 32\n",
    "\n",
    "print(\"Loading data...\")\n",
    "\n",
    "#download data\n",
    "dataset = datasets.load_dataset('ucberkeley-dlab/measuring-hate-speech', 'binary')   \n",
    "\n",
    "# Read data\n",
    "df = dataset['train'].to_pandas()\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.hatespeech.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(document: str) -> list:\n",
    "    \"\"\"\n",
    "    convert text to lowercase\n",
    "    remove no latin caracters \n",
    "    remove punctuation \n",
    "    remove extra spaces\n",
    "    do stemming text\n",
    "    \"\"\"\n",
    "    document = document.lower()\n",
    "    document = remove_stopwords(document)\n",
    "    document = re.sub('\\n', ' ', document)\n",
    "    document = re.sub('[^a-zA-Z]|[0-9]', ' ', document)\n",
    "    document = re.sub('\\s+', ' ', document)\n",
    "    p = PorterStemmer()\n",
    "    document = p.stem_sentence(document)\n",
    "    return document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text']=df.text.apply(preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['comment_id',\n",
    "'annotator_id',\n",
    "'platform',\n",
    "'sentiment',\n",
    "'respect',\n",
    "'insult',\n",
    "'humiliate',\n",
    "'status',\n",
    "'dehumanize',\n",
    "'violence',\n",
    "'genocide',\n",
    "'attack_defend',\n",
    "'hatespeech',\n",
    "'hate_speech_score',\n",
    "'text',\n",
    "'infitms',\n",
    "'outfitms',\n",
    "'annotator_severity',\n",
    "'std_err',\n",
    "'annotator_infitms',\n",
    "'annotator_outfitms',\n",
    "'hypothesis',\n",
    "'target_race_asian',\n",
    "'target_race_black',\n",
    "'target_race_latinx',\n",
    "'target_race_middle_eastern',\n",
    "'target_race_native_american',\n",
    "'target_race_pacific_islander',\n",
    "'target_race_white',\n",
    "'target_race_other',\n",
    "'target_race',\n",
    "'target_religion_atheist',\n",
    "'target_religion_buddhist',\n",
    "'target_religion_christian',\n",
    "'target_religion_hindu',\n",
    "'target_religion_jewish',\n",
    "'target_religion_mormon',\n",
    "'target_religion_muslim',\n",
    "'target_religion_other',\n",
    "'target_religion',\n",
    "'target_origin_immigrant',\n",
    "'target_origin_migrant_worker',\n",
    "'target_origin_specific_country',\n",
    "'target_origin_undocumented',\n",
    "'target_origin_other',\n",
    "'target_origin',\n",
    "'target_gender_men',\n",
    "'target_gender_non_binary',\n",
    "'target_gender_transgender_men',\n",
    "'target_gender_transgender_unspecified',\n",
    "'target_gender_transgender_women',\n",
    "'target_gender_women',\n",
    "'target_gender_other',\n",
    "'target_gender',\n",
    "'target_sexuality_bisexual',\n",
    "'target_sexuality_gay',\n",
    "'target_sexuality_lesbian',\n",
    "'target_sexuality_straight',\n",
    "'target_sexuality_other',\n",
    "'target_sexuality',\n",
    "'target_age_children',\n",
    "'target_age_teenagers',\n",
    "'target_age_young_adults',\n",
    "'target_age_middle_aged',\n",
    "'target_age_seniors',\n",
    "'target_age_other',\n",
    "'target_age',\n",
    "'target_disability_physical',\n",
    "'target_disability_cognitive',\n",
    "'target_disability_neurological',\n",
    "'target_disability_visually_impaired',\n",
    "'target_disability_hearing_impaired',\n",
    "'target_disability_unspecific',\n",
    "'target_disability_other',\n",
    "'target_disability',\n",
    "'annotator_gender',\n",
    "'annotator_trans',\n",
    "'annotator_educ',\n",
    "'annotator_income',\n",
    "'annotator_ideology',\n",
    "'annotator_gender_men',\n",
    "'annotator_gender_women',\n",
    "'annotator_gender_non_binary',\n",
    "'annotator_gender_prefer_not_to_say',\n",
    "'annotator_gender_self_describe',\n",
    "'annotator_transgender',\n",
    "'annotator_cisgender',\n",
    "'annotator_transgender_prefer_not_to_say',\n",
    "'annotator_education_some_high_school',\n",
    "'annotator_education_high_school_grad',\n",
    "'annotator_education_some_college',\n",
    "'annotator_education_college_grad_aa',\n",
    "'annotator_education_college_grad_ba',\n",
    "'annotator_education_professional_degree',\n",
    "'annotator_education_masters',\n",
    "'annotator_education_phd',\n",
    "'annotator_income_<10k',\n",
    "'annotator_income_10k-50k',\n",
    "'annotator_income_50k-100k',\n",
    "'annotator_income_100k-200k',\n",
    "'annotator_income_>200k',\n",
    "'annotator_ideology_extremeley_conservative',\n",
    "'annotator_ideology_conservative',\n",
    "'annotator_ideology_slightly_conservative',\n",
    "'annotator_ideology_neutral',\n",
    "'annotator_ideology_slightly_liberal',\n",
    "'annotator_ideology_liberal',\n",
    "'annotator_ideology_extremeley_liberal',\n",
    "'annotator_ideology_no_opinion',\n",
    "'annotator_race_asian',\n",
    "'annotator_race_black',\n",
    "'annotator_race_latinx',\n",
    "'annotator_race_middle_eastern',\n",
    "'annotator_race_native_american',\n",
    "'annotator_race_pacific_islander',\n",
    "'annotator_race_white',\n",
    "'annotator_race_other',\n",
    "'annotator_age',\n",
    "'annotator_religion_atheist',\n",
    "'annotator_religion_buddhist',\n",
    "'annotator_religion_christian',\n",
    "'annotator_religion_hindu',\n",
    "'annotator_religion_jewish',\n",
    "'annotator_religion_mormon',\n",
    "'annotator_religion_muslim',\n",
    "'annotator_religion_nothing',\n",
    "'annotator_religion_other',\n",
    "'annotator_sexuality_bisexual',\n",
    "'annotator_sexuality_gay',\n",
    "'annotator_sexuality_straight',\n",
    "'annotator_sexuality_other']]\n",
    "y = df.hatespeech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Replace hatespeech == 1 with 2** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace 1 with 2 in y\n",
    "y = [ 2.0 if x==1 else x for x in y ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Split in train and test data** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_validation, X_test, y_train_validation, y_test = train_test_split(X,y,\n",
    "                                                    random_state=1,test_size=0.3)\n",
    "\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(X_train_validation, \n",
    "                                                    y_train_validation, \n",
    "                                                    random_state=1,test_size=0.33)\n",
    "\n",
    "print('Number of rows in the total set: {}'.format(df.shape[0]))\n",
    "print('Number of rows in the training set: {}'.format(len(X_train)))\n",
    "print('Number of rows in the validation set: {}'.format(len(X_validation)))\n",
    "print('Number of rows in the test set: {}'.format(len(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "max_words = 1000\n",
    "max_len = 150\n",
    "\n",
    "tok = Tokenizer(num_words=max_words)\n",
    "tok.fit_on_texts(X_train)\n",
    "sequences = tok.texts_to_sequences(X_train)\n",
    "sequences_matrix = sequence.pad_sequences(sequences,maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RNN():\n",
    "    from keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding\n",
    "    from keras.models import Model\n",
    "    inputs = Input(name='inputs',shape=[max_len])\n",
    "    layer = Embedding(max_words,50,input_length=max_len)(inputs)\n",
    "    layer = LSTM(128)(layer)\n",
    "    layer = Dense(128,name='FC1')(layer)\n",
    "    layer = Activation('relu')(layer)\n",
    "    layer = Dropout(0.5)(layer)\n",
    "    layer = Dense(1,name='out_layer')(layer)\n",
    "    layer = Activation('sigmoid')(layer)\n",
    "    model = Model(inputs=inputs,outputs=layer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop,Adam\n",
    "\n",
    "model = RNN()\n",
    "model.summary()\n",
    "model.compile(loss='binary_crossentropy',optimizer=RMSprop(),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(sequences_matrix,y_train,batch_size=128,epochs=10,\n",
    "          validation_split=0.2,callbacks=[EarlyStopping(monitor='val_loss',min_delta=0.0001)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sequences = tok.texts_to_sequences(X_test)\n",
    "test_sequences_matrix = sequence.pad_sequences(test_sequences,maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accr = model.evaluate(test_sequences_matrix,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}'.format(accr[0],accr[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s, (at, al) = plt.subplots(2,1)\n",
    "at.plot(history.history['accuracy'], c= 'b')\n",
    "at.plot(history.history['val_accuracy'], c='r')\n",
    "at.set_title('model accuracy')\n",
    "at.set_ylabel('accuracy')\n",
    "at.set_xlabel('epoch')\n",
    "at.legend(['LSTM_train', 'LSTM_val'], loc='upper left')\n",
    "\n",
    "al.plot(history.history['loss'], c='m')\n",
    "al.plot(history.history['val_loss'], c='c')\n",
    "al.set_title('model loss')\n",
    "al.set_ylabel('loss')\n",
    "al.set_xlabel('epoch')\n",
    "al.legend(['train', 'val'], loc = 'upper left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pred = model.predict(X_test, batch_size=100, verbose=1) \n",
    "model_predicted = np.argmax(model_pred, axis=1) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_report = classification_report(np.argmax(y_test, axis=1), model_predicted)  \n",
    "print(pred_report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('env_tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5de9ea968598f77146e9bcf7403aafc4990d0b8fd820669c1cc9c3a0b1879543"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
