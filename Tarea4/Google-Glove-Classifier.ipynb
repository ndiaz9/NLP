{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import logging\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# remove warnings\n",
    "logging.basicConfig(level=logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(126646, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_character_text</th>\n",
       "      <th>spoken_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Miss Hoover</td>\n",
       "      <td>No, actually, it was a little of both. Sometim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lisa Simpson</td>\n",
       "      <td>Where's Mr. Bergstrom?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Miss Hoover</td>\n",
       "      <td>I don't know. Although I'd sure like to talk t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lisa Simpson</td>\n",
       "      <td>That life is worth living.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Edna Krabappel-Flanders</td>\n",
       "      <td>The polls will be open from now until the end ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        raw_character_text                                       spoken_words\n",
       "0              Miss Hoover  No, actually, it was a little of both. Sometim...\n",
       "1             Lisa Simpson                             Where's Mr. Bergstrom?\n",
       "2              Miss Hoover  I don't know. Although I'd sure like to talk t...\n",
       "3             Lisa Simpson                         That life is worth living.\n",
       "4  Edna Krabappel-Flanders  The polls will be open from now until the end ..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents = pd.read_csv('./datos/simpsons_dataset.csv')\n",
    "documents = documents.dropna()\n",
    "documents = documents.reset_index(drop=True)\n",
    "documents = documents.drop_duplicates()\n",
    "print(documents.shape)\n",
    "documents.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2_/4zyrcgrn3vl04w2zb0j8n8_r0000gn/T/ipykernel_6384/4165437492.py:8: DeprecationWarning: Call to deprecated `glove2word2vec` (KeyedVectors.load_word2vec_format(.., binary=False, no_header=True) loads GLoVE text vectors.).\n",
      "  glove2word2vec(glove_filename, word2vec_output_file)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(400000, 100)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We just need to run this code once, the function glove2word2vec saves the Glove embeddings in the word2vec format \n",
    "# that will be loaded in the next section\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "\n",
    "glove_filename = './datos/glove.6B.100d.txt'\n",
    "\n",
    "word2vec_output_file = glove_filename+'.word2vec'\n",
    "glove2word2vec(glove_filename, word2vec_output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "# load the Stanford GloVe model\n",
    "word2vec_output_file = glove_filename+'.word2vec'\n",
    "model = KeyedVectors.load_word2vec_format(word2vec_output_file, binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "King:  [-0.32307  -0.87616   0.21977   0.25268   0.22976   0.7388   -0.37954\n",
      " -0.35307  -0.84369  -1.1113   -0.30266   0.33178  -0.25113   0.30448\n",
      " -0.077491 -0.89815   0.092496 -1.1407   -0.58324   0.66869  -0.23122\n",
      " -0.95855   0.28262  -0.078848  0.75315   0.26584   0.3422   -0.33949\n",
      "  0.95608   0.065641  0.45747   0.39835   0.57965   0.39267  -0.21851\n",
      "  0.58795  -0.55999   0.63368  -0.043983 -0.68731  -0.37841   0.38026\n",
      "  0.61641  -0.88269  -0.12346  -0.37928  -0.38318   0.23868   0.6685\n",
      " -0.43321  -0.11065   0.081723  1.1569    0.78958  -0.21223  -2.3211\n",
      " -0.67806   0.44561   0.65707   0.1045    0.46217   0.19912   0.25802\n",
      "  0.057194  0.53443  -0.43133  -0.34311   0.59789  -0.58417   0.068995\n",
      "  0.23944  -0.85181   0.30379  -0.34177  -0.25746  -0.031101 -0.16285\n",
      "  0.45169  -0.91627   0.64521   0.73281  -0.22752   0.30226   0.044801\n",
      " -0.83741   0.55006  -0.52506  -1.7357    0.4751   -0.70487   0.056939\n",
      " -0.7132    0.089623  0.41394  -1.3363   -0.61915  -0.33089  -0.52881\n",
      "  0.16483  -0.98878 ]\n"
     ]
    }
   ],
   "source": [
    "#Show a word embedding\n",
    "print('King: ',model.get_vector('king'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_character_text</th>\n",
       "      <th>spoken_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Miss Hoover</td>\n",
       "      <td>No, actually, it was a little of both. Sometim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lisa Simpson</td>\n",
       "      <td>Where's Mr. Bergstrom?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Miss Hoover</td>\n",
       "      <td>I don't know. Although I'd sure like to talk t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lisa Simpson</td>\n",
       "      <td>That life is worth living.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Edna Krabappel-Flanders</td>\n",
       "      <td>The polls will be open from now until the end ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        raw_character_text                                       spoken_words\n",
       "0              Miss Hoover  No, actually, it was a little of both. Sometim...\n",
       "1             Lisa Simpson                             Where's Mr. Bergstrom?\n",
       "2              Miss Hoover  I don't know. Although I'd sure like to talk t...\n",
       "3             Lisa Simpson                         That life is worth living.\n",
       "4  Edna Krabappel-Flanders  The polls will be open from now until the end ..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert df to dictionary of lists key first column value second column\n",
    "def convert_to_dict(df):\n",
    "    characters = {}\n",
    "    for i in range(len(documents)):\n",
    "        row = documents.iloc[i]\n",
    "        key = row['raw_character_text'].lower()\n",
    "        if key not in characters:\n",
    "            characters[key] = []\n",
    "        characters[key].append(row['spoken_words'])\n",
    "    return characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "characters = convert_to_dict(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_characters_with_less_than_five_sentences(characters):\n",
    "    filtered_characters = {}\n",
    "    for key, value in characters.items():\n",
    "        if len(value) > 5:\n",
    "            filtered_characters[key] = value\n",
    "    return filtered_characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "characters = filter_characters_with_less_than_five_sentences(characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract vector for a sentence\n",
    "def get_vector_sentence(sentence: str, model: KeyedVectors):\n",
    "    sentence = sentence.lower()\n",
    "    words = sentence.split()\n",
    "    vector = np.zeros(100)\n",
    "    counter = 0\n",
    "    for word in words:\n",
    "        try:\n",
    "            vector += model.get_vector(word)\n",
    "            counter += 1\n",
    "        except:\n",
    "            pass\n",
    "    if counter > 0:\n",
    "        vector = vector / counter\n",
    "    return vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-4.16756973e-02,  2.20105797e-01,  4.33127097e-01, -2.99525002e-01,\n",
       "       -2.36539803e-01,  2.56168398e-01, -1.82075300e-01,  9.35989976e-02,\n",
       "       -2.26369873e-03, -1.62461992e-02,  3.50033002e-01,  3.96226041e-02,\n",
       "        6.35688014e-02,  1.38804903e-01, -1.21304397e-01, -1.02700445e-01,\n",
       "        1.70876680e-01,  2.78798301e-01, -6.20794398e-01,  3.39901002e-01,\n",
       "        1.05124820e-01, -2.98347034e-02,  1.16399007e-01, -2.67723906e-01,\n",
       "        1.87131000e-01,  1.26932808e-01, -4.64455090e-01, -6.56939998e-01,\n",
       "        3.25197880e-01, -3.69602996e-01, -1.40659975e-02,  7.84993008e-01,\n",
       "        6.52636515e-02,  1.44387382e-01,  2.03569971e-02,  2.58452199e-01,\n",
       "       -2.33882001e-01,  2.03594780e-01,  2.36797002e-01, -3.10310204e-01,\n",
       "       -3.41002197e-01, -1.36337866e-01,  7.51800984e-02, -5.39280000e-01,\n",
       "       -3.15784391e-01,  1.40125496e-01,  1.16979796e-01, -4.33540998e-01,\n",
       "        7.88982997e-02, -9.76410013e-01, -1.31981299e-01,  9.49864600e-02,\n",
       "        7.50204956e-02,  1.14306601e+00,  1.69722994e-02, -2.32139004e+00,\n",
       "        1.18204300e-01,  1.27811404e-01,  1.55960402e+00,  3.87273897e-01,\n",
       "       -4.71077986e-02,  9.34049093e-01, -3.99948706e-01,  4.02332978e-02,\n",
       "        8.49210012e-01, -9.48889956e-02,  4.99034493e-01,  3.26404404e-01,\n",
       "       -8.67741991e-02, -2.67001896e-01,  7.45997578e-04, -1.26721001e-01,\n",
       "       -1.57430988e-02, -3.44435298e-01,  8.97639617e-03,  2.17669999e-01,\n",
       "       -2.39718998e-01, -9.90214013e-02, -4.90900100e-01,  1.86101027e-02,\n",
       "        5.18117005e-01,  1.49716005e-01, -5.29292010e-01, -5.64660013e-02,\n",
       "       -1.58785998e+00, -2.50580002e-01, -4.71812767e-02, -5.57026953e-02,\n",
       "       -3.10270001e-01, -2.73026503e-01, -1.99920798e-01,  2.72656158e-03,\n",
       "        1.24451004e-01,  4.04074939e-02, -5.88904004e-01, -3.01355038e-02,\n",
       "       -1.39184100e-01, -2.82419100e-01,  3.78983995e-01,  4.72023998e-01])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test get_vector_sentence function\n",
    "get_vector_sentence('Kids, You Tried Your Best And You Failed Miserably. The Lesson Is, Never Try.', model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sublist(list, n):\n",
    "    return [list[i:i+n] for i in range(0, len(list), n)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract vectors for all characters in groups of five sentences\n",
    "def get_vectors_characters(characters: dict) -> dict:\n",
    "    characters_vectors = {}\n",
    "    for key, value in characters.items():\n",
    "        if key not in characters_vectors:\n",
    "            characters_vectors[key] = []\n",
    "        sentences_big = get_sublist(value, 5)\n",
    "        for sentences in sentences_big:\n",
    "            sentences_counter = 0\n",
    "            sentence_vector = np.zeros(100)\n",
    "            for sentence in sentences:\n",
    "                sentence_vector += get_vector_sentence(sentence, model)\n",
    "                sentences_counter += 1\n",
    "            if sentences_counter > 0:\n",
    "                sentence_vector = sentence_vector / sentences_counter\n",
    "            characters_vectors[key].append(sentence_vector)\n",
    "    return characters_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "characters_vectors= get_vectors_characters(characters)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1252"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(characters_vectors.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "characters_selected = {}\n",
    "for key, value in characters_vectors.items():\n",
    "    if len(characters_vectors[key]) > 1000:\n",
    "        characters_selected[key] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "lineas = ([ len(characters_selected[key]) for key in characters_selected.keys()])\n",
    "\n",
    "X = np.zeros((np.sum(lineas), 100))\n",
    "for key, value in characters_selected.items():\n",
    "    for i in range(len(value)):\n",
    "        X[i*len(value):(i+1)*len(value), :] = value[i]\n",
    "\n",
    "y = np.concatenate( [np.zeros(lineas[0]), np.ones(lineas[1]),np.ones(lineas[2])*2,np.ones(lineas[3])*3]).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import misc  \n",
    "from keras import layers  \n",
    "from keras.layers import Flatten, Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D, Dropout  \n",
    "from keras.models import Sequential, Model, load_model  \n",
    "from keras.utils import layer_utils, np_utils  \n",
    "from keras.utils.data_utils import get_file  \n",
    "from keras.applications.imagenet_utils import preprocess_input  \n",
    "from keras.utils.vis_utils import model_to_dot  \n",
    "from keras.callbacks import ModelCheckpoint  \n",
    "from sklearn.metrics import confusion_matrix, classification_report  \n",
    "import tensorflow as tf  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Arquitectura 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_simple_nn():  \n",
    "    model = Sequential()\n",
    "    model.add(Dense(100,  activation='relu', name=\"Input_layer\"))\n",
    "    model.add(Dense(50, activation='relu', name=\"Hidden_layer_1\"))\n",
    "    model.add(Dense(50, activation='relu', name=\"Hidden_layer_2\"))\n",
    "    model.add(Dense(4, activation='softmax', name=\"Output_layer\"))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "snn_model = create_simple_nn()  \n",
    "snn_model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['acc', 'mse'])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_categorical(a):\n",
    "    b = np.zeros((a.size, a.max()+1))\n",
    "    b[np.arange(a.size),a] = 1\n",
    "    return b\n",
    "\n",
    "y_train_categorical = convert_to_categorical(y_train)\n",
    "y_test_categorical = convert_to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-12 22:44:05.051469: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97/97 [==============================] - 0s 2ms/step - loss: 1.2901 - acc: 0.4236 - mse: 0.1752 - val_loss: 1.2422 - val_acc: 0.4293 - val_mse: 0.1691\n",
      "Epoch 2/10\n",
      "97/97 [==============================] - 0s 788us/step - loss: 1.1826 - acc: 0.5280 - mse: 0.1612 - val_loss: 1.1336 - val_acc: 0.5934 - val_mse: 0.1540\n",
      "Epoch 3/10\n",
      "97/97 [==============================] - 0s 745us/step - loss: 1.0497 - acc: 0.6124 - mse: 0.1422 - val_loss: 0.9962 - val_acc: 0.5934 - val_mse: 0.1342\n",
      "Epoch 4/10\n",
      "97/97 [==============================] - 0s 759us/step - loss: 0.9094 - acc: 0.6124 - mse: 0.1222 - val_loss: 0.8714 - val_acc: 0.5934 - val_mse: 0.1174\n",
      "Epoch 5/10\n",
      "97/97 [==============================] - 0s 735us/step - loss: 0.7912 - acc: 0.6304 - mse: 0.1055 - val_loss: 0.7636 - val_acc: 0.7678 - val_mse: 0.1005\n",
      "Epoch 6/10\n",
      "97/97 [==============================] - 0s 744us/step - loss: 0.6793 - acc: 0.7825 - mse: 0.0880 - val_loss: 0.6476 - val_acc: 0.7678 - val_mse: 0.0825\n",
      "Epoch 7/10\n",
      "97/97 [==============================] - 0s 747us/step - loss: 0.5665 - acc: 0.8607 - mse: 0.0703 - val_loss: 0.5400 - val_acc: 0.8920 - val_mse: 0.0651\n",
      "Epoch 8/10\n",
      "97/97 [==============================] - 0s 748us/step - loss: 0.4766 - acc: 0.8945 - mse: 0.0575 - val_loss: 0.4650 - val_acc: 0.8920 - val_mse: 0.0558\n",
      "Epoch 9/10\n",
      "97/97 [==============================] - 0s 746us/step - loss: 0.4181 - acc: 0.8945 - mse: 0.0507 - val_loss: 0.4181 - val_acc: 0.8920 - val_mse: 0.0508\n",
      "Epoch 10/10\n",
      "97/97 [==============================] - 0s 745us/step - loss: 0.3836 - acc: 0.8945 - mse: 0.0476 - val_loss: 0.3887 - val_acc: 0.8920 - val_mse: 0.0484\n"
     ]
    }
   ],
   "source": [
    "snn = snn_model.fit(x=X_train, y=y_train_categorical, batch_size=100, epochs=10, validation_data=(X_test, y_test_categorical), shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Input_layer (Dense)         (None, 100)               10100     \n",
      "                                                                 \n",
      " Hidden_layer_1 (Dense)      (None, 50)                5050      \n",
      "                                                                 \n",
      " Hidden_layer_2 (Dense)      (None, 50)                2550      \n",
      "                                                                 \n",
      " Output_layer (Dense)        (None, 4)                 204       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 17,904\n",
      "Trainable params: 17,904\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "snn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76/76 [==============================] - 0s 369us/step - loss: 0.3887 - acc: 0.8920 - mse: 0.0484\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.38870611786842346, 0.8919587731361389, 0.04840464890003204]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snn_model.evaluate(X_test, y_test_categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 0s 368us/step\n"
     ]
    }
   ],
   "source": [
    "snn_pred = snn_model.predict(X_test, batch_size=100, verbose=1) \n",
    "snn_predicted = np.argmax(snn_pred, axis=1)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['lisa simpson', 'bart simpson', 'homer simpson', 'marge simpson'])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "characters_selected.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      1.00      0.90       423\n",
      "           1       0.80      0.82      0.81       492\n",
      "           2       0.93      0.90      0.92      1041\n",
      "           3       1.00      0.85      0.92       469\n",
      "\n",
      "    accuracy                           0.89      2425\n",
      "   macro avg       0.89      0.89      0.89      2425\n",
      "weighted avg       0.90      0.89      0.89      2425\n",
      "\n"
     ]
    }
   ],
   "source": [
    "snn_report = classification_report(np.argmax(y_test_categorical, axis=1), snn_predicted)  \n",
    "print(snn_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Arquitectura 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_simple_nn():  \n",
    "    model = Sequential()\n",
    "    model.add(Dense(100,  activation='relu', name=\"Input_layer\"))\n",
    "    model.add(Dense(100, activation='relu', name=\"Hidden_layer_1\"))\n",
    "    model.add(Dense(100, activation='relu', name=\"Hidden_layer_2\"))\n",
    "    model.add(Dense(50, activation='relu', name=\"Hidden_layer_3\"))\n",
    "    model.add(Dense(4, activation='softmax', name=\"Output_layer\"))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "snn_model = create_simple_nn()  \n",
    "snn_model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['acc', 'mse'])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_categorical(a):\n",
    "    b = np.zeros((a.size, a.max()+1))\n",
    "    b[np.arange(a.size),a] = 1\n",
    "    return b\n",
    "\n",
    "y_train_categorical = convert_to_categorical(y_train)\n",
    "y_test_categorical = convert_to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 1.3174 - acc: 0.3954 - mse: 0.1785 - val_loss: 1.2500 - val_acc: 0.4293 - val_mse: 0.1692\n",
      "Epoch 2/10\n",
      "97/97 [==============================] - 0s 1ms/step - loss: 1.1843 - acc: 0.5266 - mse: 0.1596 - val_loss: 1.1239 - val_acc: 0.5934 - val_mse: 0.1503\n",
      "Epoch 3/10\n",
      "97/97 [==============================] - 0s 1ms/step - loss: 1.0168 - acc: 0.6124 - mse: 0.1337 - val_loss: 0.9251 - val_acc: 0.5934 - val_mse: 0.1195\n",
      "Epoch 4/10\n",
      "97/97 [==============================] - 0s 1ms/step - loss: 0.7933 - acc: 0.7267 - mse: 0.0997 - val_loss: 0.7051 - val_acc: 0.8920 - val_mse: 0.0869\n",
      "Epoch 5/10\n",
      "97/97 [==============================] - 0s 1ms/step - loss: 0.5992 - acc: 0.8835 - mse: 0.0724 - val_loss: 0.5459 - val_acc: 0.8920 - val_mse: 0.0654\n",
      "Epoch 6/10\n",
      "97/97 [==============================] - 0s 1ms/step - loss: 0.4757 - acc: 0.8945 - mse: 0.0567 - val_loss: 0.4563 - val_acc: 0.8920 - val_mse: 0.0539\n",
      "Epoch 7/10\n",
      "97/97 [==============================] - 0s 1ms/step - loss: 0.4053 - acc: 0.8945 - mse: 0.0490 - val_loss: 0.4098 - val_acc: 0.8920 - val_mse: 0.0490\n",
      "Epoch 8/10\n",
      "97/97 [==============================] - 0s 1ms/step - loss: 0.3688 - acc: 0.8941 - mse: 0.0462 - val_loss: 0.3716 - val_acc: 0.8920 - val_mse: 0.0466\n",
      "Epoch 9/10\n",
      "97/97 [==============================] - 0s 1ms/step - loss: 0.3480 - acc: 0.8931 - mse: 0.0454 - val_loss: 0.3585 - val_acc: 0.8920 - val_mse: 0.0461\n",
      "Epoch 10/10\n",
      "97/97 [==============================] - 0s 1ms/step - loss: 0.3321 - acc: 0.8945 - mse: 0.0448 - val_loss: 0.3364 - val_acc: 0.8920 - val_mse: 0.0455\n"
     ]
    }
   ],
   "source": [
    "snn = snn_model.fit(x=X_train, y=y_train_categorical, batch_size=100, epochs=10, validation_data=(X_test, y_test_categorical), shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Input_layer (Dense)         (None, 100)               10100     \n",
      "                                                                 \n",
      " Hidden_layer_1 (Dense)      (None, 100)               10100     \n",
      "                                                                 \n",
      " Hidden_layer_2 (Dense)      (None, 100)               10100     \n",
      "                                                                 \n",
      " Hidden_layer_3 (Dense)      (None, 50)                5050      \n",
      "                                                                 \n",
      " Output_layer (Dense)        (None, 4)                 204       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 35,554\n",
      "Trainable params: 35,554\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "snn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76/76 [==============================] - 0s 398us/step - loss: 0.3364 - acc: 0.8920 - mse: 0.0455\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.33636176586151123, 0.8919587731361389, 0.04549537971615791]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snn_model.evaluate(X_test, y_test_categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 0s 451us/step\n"
     ]
    }
   ],
   "source": [
    "snn_pred = snn_model.predict(X_test, batch_size=100, verbose=1) \n",
    "snn_predicted = np.argmax(snn_pred, axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      1.00      0.90       423\n",
      "           1       0.80      0.82      0.81       492\n",
      "           2       0.93      0.90      0.92      1041\n",
      "           3       1.00      0.85      0.92       469\n",
      "\n",
      "    accuracy                           0.89      2425\n",
      "   macro avg       0.89      0.89      0.89      2425\n",
      "weighted avg       0.90      0.89      0.89      2425\n",
      "\n"
     ]
    }
   ],
   "source": [
    "snn_report = classification_report(np.argmax(y_test_categorical, axis=1), snn_predicted)  \n",
    "print(snn_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Arquitectura 3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_simple_nn():  \n",
    "    model = Sequential()\n",
    "    model.add(Dense(100,  activation='relu', name=\"Input_layer\"))\n",
    "    model.add(Dense(80, activation='relu', name=\"Hidden_layer_1\"))\n",
    "    model.add(Dense(80, activation='relu', name=\"Hidden_layer_2\"))\n",
    "    model.add(Dense(50, activation='relu', name=\"Hidden_layer_3\"))\n",
    "    model.add(Dense(4, activation='softmax', name=\"Output_layer\"))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "snn_model = create_simple_nn()  \n",
    "snn_model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['acc', 'mse'])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_categorical(a):\n",
    "    b = np.zeros((a.size, a.max()+1))\n",
    "    b[np.arange(a.size),a] = 1\n",
    "    return b\n",
    "\n",
    "y_train_categorical = convert_to_categorical(y_train)\n",
    "y_test_categorical = convert_to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "97/97 [==============================] - 0s 2ms/step - loss: 1.2988 - acc: 0.4105 - mse: 0.1762 - val_loss: 1.2480 - val_acc: 0.4293 - val_mse: 0.1696\n",
      "Epoch 2/20\n",
      "97/97 [==============================] - 0s 976us/step - loss: 1.1837 - acc: 0.5598 - mse: 0.1606 - val_loss: 1.1180 - val_acc: 0.5934 - val_mse: 0.1515\n",
      "Epoch 3/20\n",
      "97/97 [==============================] - 0s 936us/step - loss: 1.0186 - acc: 0.6124 - mse: 0.1366 - val_loss: 0.9555 - val_acc: 0.5934 - val_mse: 0.1276\n",
      "Epoch 4/20\n",
      "97/97 [==============================] - 0s 928us/step - loss: 0.8543 - acc: 0.6141 - mse: 0.1133 - val_loss: 0.8088 - val_acc: 0.7175 - val_mse: 0.1068\n",
      "Epoch 5/20\n",
      "97/97 [==============================] - 0s 921us/step - loss: 0.7135 - acc: 0.7519 - mse: 0.0927 - val_loss: 0.6758 - val_acc: 0.8920 - val_mse: 0.0868\n",
      "Epoch 6/20\n",
      "97/97 [==============================] - 0s 918us/step - loss: 0.5847 - acc: 0.8307 - mse: 0.0740 - val_loss: 0.5576 - val_acc: 0.8920 - val_mse: 0.0702\n",
      "Epoch 7/20\n",
      "97/97 [==============================] - 0s 920us/step - loss: 0.4913 - acc: 0.8945 - mse: 0.0621 - val_loss: 0.4744 - val_acc: 0.8920 - val_mse: 0.0605\n",
      "Epoch 8/20\n",
      "97/97 [==============================] - 0s 929us/step - loss: 0.4193 - acc: 0.8945 - mse: 0.0537 - val_loss: 0.4133 - val_acc: 0.8920 - val_mse: 0.0538\n",
      "Epoch 9/20\n",
      "97/97 [==============================] - 0s 929us/step - loss: 0.3719 - acc: 0.8945 - mse: 0.0485 - val_loss: 0.3694 - val_acc: 0.8920 - val_mse: 0.0476\n",
      "Epoch 10/20\n",
      "97/97 [==============================] - 0s 897us/step - loss: 0.3408 - acc: 0.8945 - mse: 0.0457 - val_loss: 0.3407 - val_acc: 0.8920 - val_mse: 0.0464\n",
      "Epoch 11/20\n",
      "97/97 [==============================] - 0s 910us/step - loss: 0.3229 - acc: 0.8945 - mse: 0.0447 - val_loss: 0.3251 - val_acc: 0.8920 - val_mse: 0.0453\n",
      "Epoch 12/20\n",
      "97/97 [==============================] - 0s 907us/step - loss: 0.3118 - acc: 0.8945 - mse: 0.0443 - val_loss: 0.3166 - val_acc: 0.8920 - val_mse: 0.0453\n",
      "Epoch 13/20\n",
      "97/97 [==============================] - 0s 918us/step - loss: 0.3076 - acc: 0.8945 - mse: 0.0445 - val_loss: 0.3162 - val_acc: 0.8920 - val_mse: 0.0451\n",
      "Epoch 14/20\n",
      "97/97 [==============================] - 0s 909us/step - loss: 0.3008 - acc: 0.8945 - mse: 0.0440 - val_loss: 0.3223 - val_acc: 0.8920 - val_mse: 0.0476\n",
      "Epoch 15/20\n",
      "97/97 [==============================] - 0s 955us/step - loss: 0.3004 - acc: 0.8920 - mse: 0.0444 - val_loss: 0.3175 - val_acc: 0.8920 - val_mse: 0.0476\n",
      "Epoch 16/20\n",
      "97/97 [==============================] - 0s 919us/step - loss: 0.3003 - acc: 0.8945 - mse: 0.0446 - val_loss: 0.3064 - val_acc: 0.8920 - val_mse: 0.0451\n",
      "Epoch 17/20\n",
      "97/97 [==============================] - 0s 919us/step - loss: 0.2968 - acc: 0.8945 - mse: 0.0444 - val_loss: 0.3077 - val_acc: 0.8920 - val_mse: 0.0462\n",
      "Epoch 18/20\n",
      "97/97 [==============================] - 0s 912us/step - loss: 0.2922 - acc: 0.8945 - mse: 0.0439 - val_loss: 0.3020 - val_acc: 0.8920 - val_mse: 0.0453\n",
      "Epoch 19/20\n",
      "97/97 [==============================] - 0s 917us/step - loss: 0.2939 - acc: 0.8945 - mse: 0.0443 - val_loss: 0.3285 - val_acc: 0.8920 - val_mse: 0.0507\n",
      "Epoch 20/20\n",
      "97/97 [==============================] - 0s 986us/step - loss: 0.2912 - acc: 0.8938 - mse: 0.0440 - val_loss: 0.2975 - val_acc: 0.8920 - val_mse: 0.0448\n"
     ]
    }
   ],
   "source": [
    "snn = snn_model.fit(x=X_train, y=y_train_categorical, batch_size=100, epochs=20, validation_data=(X_test, y_test_categorical), shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Input_layer (Dense)         (None, 100)               10100     \n",
      "                                                                 \n",
      " Hidden_layer_1 (Dense)      (None, 80)                8080      \n",
      "                                                                 \n",
      " Hidden_layer_2 (Dense)      (None, 80)                6480      \n",
      "                                                                 \n",
      " Hidden_layer_3 (Dense)      (None, 50)                4050      \n",
      "                                                                 \n",
      " Output_layer (Dense)        (None, 4)                 204       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 28,914\n",
      "Trainable params: 28,914\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "snn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76/76 [==============================] - 0s 393us/step - loss: 0.2975 - acc: 0.8920 - mse: 0.0448\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.29747289419174194, 0.8919587731361389, 0.04478830099105835]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snn_model.evaluate(X_test, y_test_categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 0s 485us/step\n"
     ]
    }
   ],
   "source": [
    "snn_pred = snn_model.predict(X_test, batch_size=100, verbose=1) \n",
    "snn_predicted = np.argmax(snn_pred, axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      1.00      0.90       423\n",
      "           1       0.80      0.82      0.81       492\n",
      "           2       0.93      0.90      0.92      1041\n",
      "           3       1.00      0.85      0.92       469\n",
      "\n",
      "    accuracy                           0.89      2425\n",
      "   macro avg       0.89      0.89      0.89      2425\n",
      "weighted avg       0.90      0.89      0.89      2425\n",
      "\n"
     ]
    }
   ],
   "source": [
    "snn_report = classification_report(np.argmax(y_test_categorical, axis=1), snn_predicted)  \n",
    "print(snn_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
