{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import spacy\n",
    "import gensim\n",
    "import logging\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# remove warnings\n",
    "logging.basicConfig(level=logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(126646, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_character_text</th>\n",
       "      <th>spoken_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Miss Hoover</td>\n",
       "      <td>No, actually, it was a little of both. Sometim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lisa Simpson</td>\n",
       "      <td>Where's Mr. Bergstrom?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Miss Hoover</td>\n",
       "      <td>I don't know. Although I'd sure like to talk t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lisa Simpson</td>\n",
       "      <td>That life is worth living.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Edna Krabappel-Flanders</td>\n",
       "      <td>The polls will be open from now until the end ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        raw_character_text                                       spoken_words\n",
       "0              Miss Hoover  No, actually, it was a little of both. Sometim...\n",
       "1             Lisa Simpson                             Where's Mr. Bergstrom?\n",
       "2              Miss Hoover  I don't know. Although I'd sure like to talk t...\n",
       "3             Lisa Simpson                         That life is worth living.\n",
       "4  Edna Krabappel-Flanders  The polls will be open from now until the end ..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents = pd.read_csv('./datos/simpsons_dataset.csv')\n",
    "documents = documents.dropna()\n",
    "documents = documents.reset_index(drop=True)\n",
    "documents = documents.drop_duplicates()\n",
    "print(documents.shape)\n",
    "documents.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2_/4zyrcgrn3vl04w2zb0j8n8_r0000gn/T/ipykernel_48029/4165437492.py:8: DeprecationWarning: Call to deprecated `glove2word2vec` (KeyedVectors.load_word2vec_format(.., binary=False, no_header=True) loads GLoVE text vectors.).\n",
      "  glove2word2vec(glove_filename, word2vec_output_file)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(400000, 100)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We just need to run this code once, the function glove2word2vec saves the Glove embeddings in the word2vec format \n",
    "# that will be loaded in the next section\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "\n",
    "glove_filename = './datos/glove.6B.100d.txt'\n",
    "\n",
    "word2vec_output_file = glove_filename+'.word2vec'\n",
    "glove2word2vec(glove_filename, word2vec_output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "# load the Stanford GloVe model\n",
    "word2vec_output_file = glove_filename+'.word2vec'\n",
    "model = KeyedVectors.load_word2vec_format(word2vec_output_file, binary=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "King:  [-0.32307  -0.87616   0.21977   0.25268   0.22976   0.7388   -0.37954\n",
      " -0.35307  -0.84369  -1.1113   -0.30266   0.33178  -0.25113   0.30448\n",
      " -0.077491 -0.89815   0.092496 -1.1407   -0.58324   0.66869  -0.23122\n",
      " -0.95855   0.28262  -0.078848  0.75315   0.26584   0.3422   -0.33949\n",
      "  0.95608   0.065641  0.45747   0.39835   0.57965   0.39267  -0.21851\n",
      "  0.58795  -0.55999   0.63368  -0.043983 -0.68731  -0.37841   0.38026\n",
      "  0.61641  -0.88269  -0.12346  -0.37928  -0.38318   0.23868   0.6685\n",
      " -0.43321  -0.11065   0.081723  1.1569    0.78958  -0.21223  -2.3211\n",
      " -0.67806   0.44561   0.65707   0.1045    0.46217   0.19912   0.25802\n",
      "  0.057194  0.53443  -0.43133  -0.34311   0.59789  -0.58417   0.068995\n",
      "  0.23944  -0.85181   0.30379  -0.34177  -0.25746  -0.031101 -0.16285\n",
      "  0.45169  -0.91627   0.64521   0.73281  -0.22752   0.30226   0.044801\n",
      " -0.83741   0.55006  -0.52506  -1.7357    0.4751   -0.70487   0.056939\n",
      " -0.7132    0.089623  0.41394  -1.3363   -0.61915  -0.33089  -0.52881\n",
      "  0.16483  -0.98878 ]\n"
     ]
    }
   ],
   "source": [
    "#Show a word embedding\n",
    "print('King: ',model.get_vector('king'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_character_text</th>\n",
       "      <th>spoken_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Miss Hoover</td>\n",
       "      <td>No, actually, it was a little of both. Sometim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lisa Simpson</td>\n",
       "      <td>Where's Mr. Bergstrom?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Miss Hoover</td>\n",
       "      <td>I don't know. Although I'd sure like to talk t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lisa Simpson</td>\n",
       "      <td>That life is worth living.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Edna Krabappel-Flanders</td>\n",
       "      <td>The polls will be open from now until the end ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        raw_character_text                                       spoken_words\n",
       "0              Miss Hoover  No, actually, it was a little of both. Sometim...\n",
       "1             Lisa Simpson                             Where's Mr. Bergstrom?\n",
       "2              Miss Hoover  I don't know. Although I'd sure like to talk t...\n",
       "3             Lisa Simpson                         That life is worth living.\n",
       "4  Edna Krabappel-Flanders  The polls will be open from now until the end ..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert df to dictionary of lists key first column value second column\n",
    "def convert_to_dict(df):\n",
    "    characters = {}\n",
    "    for i in range(len(documents)):\n",
    "        row = documents.iloc[i]\n",
    "        key = row['raw_character_text'].lower()\n",
    "        if key not in characters:\n",
    "            characters[key] = []\n",
    "        characters[key].append(row['spoken_words'])\n",
    "    return characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "characters = convert_to_dict(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_characters_with_less_than_five_sentences(characters):\n",
    "    filtered_characters = {}\n",
    "    for key, value in characters.items():\n",
    "        if len(value) > 5:\n",
    "            filtered_characters[key] = value\n",
    "    return filtered_characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "characters = filter_characters_with_less_than_five_sentences(characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract vector for a sentence\n",
    "def get_vector_sentence(sentence: str, model: KeyedVectors):\n",
    "    sentence = sentence.lower()\n",
    "    words = sentence.split()\n",
    "    vector = np.zeros(100)\n",
    "    counter = 0\n",
    "    for word in words:\n",
    "        try:\n",
    "            vector += model.get_vector(word)\n",
    "            counter += 1\n",
    "        except:\n",
    "            pass\n",
    "    if counter > 0:\n",
    "        vector = vector / counter\n",
    "    return vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-4.16756973e-02,  2.20105797e-01,  4.33127097e-01, -2.99525002e-01,\n",
       "       -2.36539803e-01,  2.56168398e-01, -1.82075300e-01,  9.35989976e-02,\n",
       "       -2.26369873e-03, -1.62461992e-02,  3.50033002e-01,  3.96226041e-02,\n",
       "        6.35688014e-02,  1.38804903e-01, -1.21304397e-01, -1.02700445e-01,\n",
       "        1.70876680e-01,  2.78798301e-01, -6.20794398e-01,  3.39901002e-01,\n",
       "        1.05124820e-01, -2.98347034e-02,  1.16399007e-01, -2.67723906e-01,\n",
       "        1.87131000e-01,  1.26932808e-01, -4.64455090e-01, -6.56939998e-01,\n",
       "        3.25197880e-01, -3.69602996e-01, -1.40659975e-02,  7.84993008e-01,\n",
       "        6.52636515e-02,  1.44387382e-01,  2.03569971e-02,  2.58452199e-01,\n",
       "       -2.33882001e-01,  2.03594780e-01,  2.36797002e-01, -3.10310204e-01,\n",
       "       -3.41002197e-01, -1.36337866e-01,  7.51800984e-02, -5.39280000e-01,\n",
       "       -3.15784391e-01,  1.40125496e-01,  1.16979796e-01, -4.33540998e-01,\n",
       "        7.88982997e-02, -9.76410013e-01, -1.31981299e-01,  9.49864600e-02,\n",
       "        7.50204956e-02,  1.14306601e+00,  1.69722994e-02, -2.32139004e+00,\n",
       "        1.18204300e-01,  1.27811404e-01,  1.55960402e+00,  3.87273897e-01,\n",
       "       -4.71077986e-02,  9.34049093e-01, -3.99948706e-01,  4.02332978e-02,\n",
       "        8.49210012e-01, -9.48889956e-02,  4.99034493e-01,  3.26404404e-01,\n",
       "       -8.67741991e-02, -2.67001896e-01,  7.45997578e-04, -1.26721001e-01,\n",
       "       -1.57430988e-02, -3.44435298e-01,  8.97639617e-03,  2.17669999e-01,\n",
       "       -2.39718998e-01, -9.90214013e-02, -4.90900100e-01,  1.86101027e-02,\n",
       "        5.18117005e-01,  1.49716005e-01, -5.29292010e-01, -5.64660013e-02,\n",
       "       -1.58785998e+00, -2.50580002e-01, -4.71812767e-02, -5.57026953e-02,\n",
       "       -3.10270001e-01, -2.73026503e-01, -1.99920798e-01,  2.72656158e-03,\n",
       "        1.24451004e-01,  4.04074939e-02, -5.88904004e-01, -3.01355038e-02,\n",
       "       -1.39184100e-01, -2.82419100e-01,  3.78983995e-01,  4.72023998e-01])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test get_vector_sentence function\n",
    "get_vector_sentence('Kids, You Tried Your Best And You Failed Miserably. The Lesson Is, Never Try.', model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sublist(list, n):\n",
    "    return [list[i:i+n] for i in range(0, len(list), n)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract vectors for all characters in groups of five sentences\n",
    "def get_vectors_characters(characters: dict) -> dict:\n",
    "    characters_vectors = {}\n",
    "    for key, value in characters.items():\n",
    "        if key not in characters_vectors:\n",
    "            characters_vectors[key] = []\n",
    "        sentences_big = get_sublist(value, 5)\n",
    "        for sentences in sentences_big:\n",
    "            sentences_counter = 0\n",
    "            sentence_vector = np.zeros(100)\n",
    "            for sentence in sentences:\n",
    "                sentence_vector += get_vector_sentence(sentence, model)\n",
    "                sentences_counter += 1\n",
    "            if sentences_counter > 0:\n",
    "                sentence_vector = sentence_vector / sentences_counter\n",
    "            characters_vectors[key].append(sentence_vector)\n",
    "    return characters_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "characters_vectors= get_vectors_characters(characters)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1252"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(characters_vectors.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
