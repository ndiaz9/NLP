{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import logging\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# remove warnings\n",
    "logging.basicConfig(level=logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(126646, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_character_text</th>\n",
       "      <th>spoken_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Miss Hoover</td>\n",
       "      <td>No, actually, it was a little of both. Sometim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lisa Simpson</td>\n",
       "      <td>Where's Mr. Bergstrom?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Miss Hoover</td>\n",
       "      <td>I don't know. Although I'd sure like to talk t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lisa Simpson</td>\n",
       "      <td>That life is worth living.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Edna Krabappel-Flanders</td>\n",
       "      <td>The polls will be open from now until the end ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        raw_character_text                                       spoken_words\n",
       "0              Miss Hoover  No, actually, it was a little of both. Sometim...\n",
       "1             Lisa Simpson                             Where's Mr. Bergstrom?\n",
       "2              Miss Hoover  I don't know. Although I'd sure like to talk t...\n",
       "3             Lisa Simpson                         That life is worth living.\n",
       "4  Edna Krabappel-Flanders  The polls will be open from now until the end ..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents = pd.read_csv('./datos/simpsons_dataset.csv')\n",
    "documents = documents.dropna()\n",
    "documents = documents.reset_index(drop=True)\n",
    "documents = documents.drop_duplicates()\n",
    "print(documents.shape)\n",
    "documents.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2_/4zyrcgrn3vl04w2zb0j8n8_r0000gn/T/ipykernel_5457/4165437492.py:8: DeprecationWarning: Call to deprecated `glove2word2vec` (KeyedVectors.load_word2vec_format(.., binary=False, no_header=True) loads GLoVE text vectors.).\n",
      "  glove2word2vec(glove_filename, word2vec_output_file)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(400000, 100)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We just need to run this code once, the function glove2word2vec saves the Glove embeddings in the word2vec format \n",
    "# that will be loaded in the next section\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "\n",
    "glove_filename = './datos/glove.6B.100d.txt'\n",
    "\n",
    "word2vec_output_file = glove_filename+'.word2vec'\n",
    "glove2word2vec(glove_filename, word2vec_output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "# load the Stanford GloVe model\n",
    "word2vec_output_file = glove_filename+'.word2vec'\n",
    "model = KeyedVectors.load_word2vec_format(word2vec_output_file, binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "King:  [-0.32307  -0.87616   0.21977   0.25268   0.22976   0.7388   -0.37954\n",
      " -0.35307  -0.84369  -1.1113   -0.30266   0.33178  -0.25113   0.30448\n",
      " -0.077491 -0.89815   0.092496 -1.1407   -0.58324   0.66869  -0.23122\n",
      " -0.95855   0.28262  -0.078848  0.75315   0.26584   0.3422   -0.33949\n",
      "  0.95608   0.065641  0.45747   0.39835   0.57965   0.39267  -0.21851\n",
      "  0.58795  -0.55999   0.63368  -0.043983 -0.68731  -0.37841   0.38026\n",
      "  0.61641  -0.88269  -0.12346  -0.37928  -0.38318   0.23868   0.6685\n",
      " -0.43321  -0.11065   0.081723  1.1569    0.78958  -0.21223  -2.3211\n",
      " -0.67806   0.44561   0.65707   0.1045    0.46217   0.19912   0.25802\n",
      "  0.057194  0.53443  -0.43133  -0.34311   0.59789  -0.58417   0.068995\n",
      "  0.23944  -0.85181   0.30379  -0.34177  -0.25746  -0.031101 -0.16285\n",
      "  0.45169  -0.91627   0.64521   0.73281  -0.22752   0.30226   0.044801\n",
      " -0.83741   0.55006  -0.52506  -1.7357    0.4751   -0.70487   0.056939\n",
      " -0.7132    0.089623  0.41394  -1.3363   -0.61915  -0.33089  -0.52881\n",
      "  0.16483  -0.98878 ]\n"
     ]
    }
   ],
   "source": [
    "#Show a word embedding\n",
    "print('King: ',model.get_vector('king'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_character_text</th>\n",
       "      <th>spoken_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Miss Hoover</td>\n",
       "      <td>No, actually, it was a little of both. Sometim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lisa Simpson</td>\n",
       "      <td>Where's Mr. Bergstrom?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Miss Hoover</td>\n",
       "      <td>I don't know. Although I'd sure like to talk t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lisa Simpson</td>\n",
       "      <td>That life is worth living.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Edna Krabappel-Flanders</td>\n",
       "      <td>The polls will be open from now until the end ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        raw_character_text                                       spoken_words\n",
       "0              Miss Hoover  No, actually, it was a little of both. Sometim...\n",
       "1             Lisa Simpson                             Where's Mr. Bergstrom?\n",
       "2              Miss Hoover  I don't know. Although I'd sure like to talk t...\n",
       "3             Lisa Simpson                         That life is worth living.\n",
       "4  Edna Krabappel-Flanders  The polls will be open from now until the end ..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert df to dictionary of lists key first column value second column\n",
    "def convert_to_dict(df):\n",
    "    characters = {}\n",
    "    for i in range(len(documents)):\n",
    "        row = documents.iloc[i]\n",
    "        key = row['raw_character_text'].lower()\n",
    "        if key not in characters:\n",
    "            characters[key] = []\n",
    "        characters[key].append(row['spoken_words'])\n",
    "    return characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "characters = convert_to_dict(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_characters_with_less_than_five_sentences(characters):\n",
    "    filtered_characters = {}\n",
    "    for key, value in characters.items():\n",
    "        if len(value) > 5:\n",
    "            filtered_characters[key] = value\n",
    "    return filtered_characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "characters = filter_characters_with_less_than_five_sentences(characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract vector for a sentence\n",
    "def get_vector_sentence(sentence: str, model: KeyedVectors):\n",
    "    sentence = sentence.lower()\n",
    "    words = sentence.split()\n",
    "    vector = np.zeros(100)\n",
    "    counter = 0\n",
    "    for word in words:\n",
    "        try:\n",
    "            vector += model.get_vector(word)\n",
    "            counter += 1\n",
    "        except:\n",
    "            pass\n",
    "    if counter > 0:\n",
    "        vector = vector / counter\n",
    "    return vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-4.16756973e-02,  2.20105797e-01,  4.33127097e-01, -2.99525002e-01,\n",
       "       -2.36539803e-01,  2.56168398e-01, -1.82075300e-01,  9.35989976e-02,\n",
       "       -2.26369873e-03, -1.62461992e-02,  3.50033002e-01,  3.96226041e-02,\n",
       "        6.35688014e-02,  1.38804903e-01, -1.21304397e-01, -1.02700445e-01,\n",
       "        1.70876680e-01,  2.78798301e-01, -6.20794398e-01,  3.39901002e-01,\n",
       "        1.05124820e-01, -2.98347034e-02,  1.16399007e-01, -2.67723906e-01,\n",
       "        1.87131000e-01,  1.26932808e-01, -4.64455090e-01, -6.56939998e-01,\n",
       "        3.25197880e-01, -3.69602996e-01, -1.40659975e-02,  7.84993008e-01,\n",
       "        6.52636515e-02,  1.44387382e-01,  2.03569971e-02,  2.58452199e-01,\n",
       "       -2.33882001e-01,  2.03594780e-01,  2.36797002e-01, -3.10310204e-01,\n",
       "       -3.41002197e-01, -1.36337866e-01,  7.51800984e-02, -5.39280000e-01,\n",
       "       -3.15784391e-01,  1.40125496e-01,  1.16979796e-01, -4.33540998e-01,\n",
       "        7.88982997e-02, -9.76410013e-01, -1.31981299e-01,  9.49864600e-02,\n",
       "        7.50204956e-02,  1.14306601e+00,  1.69722994e-02, -2.32139004e+00,\n",
       "        1.18204300e-01,  1.27811404e-01,  1.55960402e+00,  3.87273897e-01,\n",
       "       -4.71077986e-02,  9.34049093e-01, -3.99948706e-01,  4.02332978e-02,\n",
       "        8.49210012e-01, -9.48889956e-02,  4.99034493e-01,  3.26404404e-01,\n",
       "       -8.67741991e-02, -2.67001896e-01,  7.45997578e-04, -1.26721001e-01,\n",
       "       -1.57430988e-02, -3.44435298e-01,  8.97639617e-03,  2.17669999e-01,\n",
       "       -2.39718998e-01, -9.90214013e-02, -4.90900100e-01,  1.86101027e-02,\n",
       "        5.18117005e-01,  1.49716005e-01, -5.29292010e-01, -5.64660013e-02,\n",
       "       -1.58785998e+00, -2.50580002e-01, -4.71812767e-02, -5.57026953e-02,\n",
       "       -3.10270001e-01, -2.73026503e-01, -1.99920798e-01,  2.72656158e-03,\n",
       "        1.24451004e-01,  4.04074939e-02, -5.88904004e-01, -3.01355038e-02,\n",
       "       -1.39184100e-01, -2.82419100e-01,  3.78983995e-01,  4.72023998e-01])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test get_vector_sentence function\n",
    "get_vector_sentence('Kids, You Tried Your Best And You Failed Miserably. The Lesson Is, Never Try.', model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sublist(list, n):\n",
    "    return [list[i:i+n] for i in range(0, len(list), n)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract vectors for all characters in groups of five sentences\n",
    "def get_vectors_characters(characters: dict) -> dict:\n",
    "    characters_vectors = {}\n",
    "    for key, value in characters.items():\n",
    "        if key not in characters_vectors:\n",
    "            characters_vectors[key] = []\n",
    "        sentences_big = get_sublist(value, 5)\n",
    "        for sentences in sentences_big:\n",
    "            sentences_counter = 0\n",
    "            sentence_vector = np.zeros(100)\n",
    "            for sentence in sentences:\n",
    "                sentence_vector += get_vector_sentence(sentence, model)\n",
    "                sentences_counter += 1\n",
    "            if sentences_counter > 0:\n",
    "                sentence_vector = sentence_vector / sentences_counter\n",
    "            characters_vectors[key].append(sentence_vector)\n",
    "    return characters_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "characters_vectors= get_vectors_characters(characters)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1252"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(characters_vectors.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "characters_selected = {}\n",
    "for key, value in characters_vectors.items():\n",
    "    if len(characters_vectors[key]) > 1000:\n",
    "        characters_selected[key] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "lineas = ([ len(characters_selected[key]) for key in characters_selected.keys()])\n",
    "\n",
    "X = np.zeros((np.sum(lineas), 100))\n",
    "for key, value in characters_selected.items():\n",
    "    for i in range(len(value)):\n",
    "        X[i*len(value):(i+1)*len(value), :] = value[i]\n",
    "\n",
    "y = np.concatenate( [np.zeros(lineas[0]), np.ones(lineas[1]),np.ones(lineas[2])*2,np.ones(lineas[3])*3]).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import misc  \n",
    "from keras import layers  \n",
    "from keras.layers import Flatten, Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D, Dropout  \n",
    "from keras.models import Sequential, Model, load_model  \n",
    "from keras.utils import layer_utils, np_utils  \n",
    "from keras.utils.data_utils import get_file  \n",
    "from keras.applications.imagenet_utils import preprocess_input  \n",
    "from keras.utils.vis_utils import model_to_dot  \n",
    "#from keras.utils import plot_model  \n",
    "from keras.initializers import glorot_uniform  \n",
    "from keras import losses  \n",
    "import keras.backend as K  \n",
    "from keras.callbacks import ModelCheckpoint  \n",
    "from sklearn.metrics import confusion_matrix, classification_report  \n",
    "import tensorflow as tf  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_simple_nn():  \n",
    "    model = Sequential()\n",
    "    model.add(Dense(100,  activation='relu', name=\"Input_layer\"))\n",
    "    model.add(Dense(50, activation='relu', name=\"Hidden_layer_1\"))\n",
    "    model.add(Dense(50, activation='relu', name=\"Hidden_layer_2\"))\n",
    "    model.add(Dense(4, activation='softmax', name=\"Output_layer\"))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "snn_model = create_simple_nn()  \n",
    "snn_model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['acc', 'mse'])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_categorical(a):\n",
    "    b = np.zeros((a.size, a.max()+1))\n",
    "    b[np.arange(a.size),a] = 1\n",
    "    return b\n",
    "\n",
    "y_train_categorical = convert_to_categorical(y_train)\n",
    "y_test_categorical = convert_to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-12 22:21:04.495037: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97/97 [==============================] - 0s 2ms/step - loss: 1.3086 - acc: 0.4093 - mse: 0.1773 - val_loss: 1.2544 - val_acc: 0.4293 - val_mse: 0.1701\n",
      "Epoch 2/10\n",
      "97/97 [==============================] - 0s 808us/step - loss: 1.2044 - acc: 0.4283 - mse: 0.1635 - val_loss: 1.1574 - val_acc: 0.4293 - val_mse: 0.1569\n",
      "Epoch 3/10\n",
      "97/97 [==============================] - 0s 838us/step - loss: 1.0819 - acc: 0.5703 - mse: 0.1461 - val_loss: 1.0123 - val_acc: 0.5934 - val_mse: 0.1355\n",
      "Epoch 4/10\n",
      "97/97 [==============================] - 0s 925us/step - loss: 0.9015 - acc: 0.7231 - mse: 0.1185 - val_loss: 0.8216 - val_acc: 0.7175 - val_mse: 0.1065\n",
      "Epoch 5/10\n",
      "97/97 [==============================] - 0s 779us/step - loss: 0.7198 - acc: 0.7558 - mse: 0.0917 - val_loss: 0.6670 - val_acc: 0.7542 - val_mse: 0.0842\n",
      "Epoch 6/10\n",
      "97/97 [==============================] - 0s 801us/step - loss: 0.5860 - acc: 0.8305 - mse: 0.0735 - val_loss: 0.5564 - val_acc: 0.8920 - val_mse: 0.0700\n",
      "Epoch 7/10\n",
      "97/97 [==============================] - 0s 796us/step - loss: 0.4996 - acc: 0.8945 - mse: 0.0631 - val_loss: 0.4868 - val_acc: 0.8920 - val_mse: 0.0616\n",
      "Epoch 8/10\n",
      "97/97 [==============================] - 0s 804us/step - loss: 0.4414 - acc: 0.8945 - mse: 0.0564 - val_loss: 0.4378 - val_acc: 0.8920 - val_mse: 0.0568\n",
      "Epoch 9/10\n",
      "97/97 [==============================] - 0s 1ms/step - loss: 0.3989 - acc: 0.8945 - mse: 0.0516 - val_loss: 0.3992 - val_acc: 0.8920 - val_mse: 0.0519\n",
      "Epoch 10/10\n",
      "97/97 [==============================] - 0s 844us/step - loss: 0.3672 - acc: 0.8945 - mse: 0.0481 - val_loss: 0.3692 - val_acc: 0.8920 - val_mse: 0.0485\n"
     ]
    }
   ],
   "source": [
    "snn = snn_model.fit(x=X_train, y=y_train_categorical, batch_size=100, epochs=10, validation_data=(X_test, y_test_categorical), shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Input_layer (Dense)         (None, 100)               10100     \n",
      "                                                                 \n",
      " Hidden_layer_1 (Dense)      (None, 50)                5050      \n",
      "                                                                 \n",
      " Hidden_layer_2 (Dense)      (None, 50)                2550      \n",
      "                                                                 \n",
      " Output_layer (Dense)        (None, 4)                 204       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 17,904\n",
      "Trainable params: 17,904\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "snn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76/76 [==============================] - 0s 362us/step - loss: 0.3692 - acc: 0.8920 - mse: 0.0485\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3692285418510437, 0.8919587731361389, 0.0485413484275341]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snn_model.evaluate(X_test, y_test_categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 0s 645us/step\n"
     ]
    }
   ],
   "source": [
    "snn_pred = snn_model.predict(X_test, batch_size=100, verbose=1) \n",
    "snn_predicted = np.argmax(snn_pred, axis=1)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['lisa simpson', 'bart simpson', 'homer simpson', 'marge simpson'])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "characters_selected.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      1.00      0.90       423\n",
      "           1       0.80      0.82      0.81       492\n",
      "           2       0.93      0.90      0.92      1041\n",
      "           3       1.00      0.85      0.92       469\n",
      "\n",
      "    accuracy                           0.89      2425\n",
      "   macro avg       0.89      0.89      0.89      2425\n",
      "weighted avg       0.90      0.89      0.89      2425\n",
      "\n"
     ]
    }
   ],
   "source": [
    "snn_report = classification_report(np.argmax(y_test_categorical, axis=1), snn_predicted)  \n",
    "print(snn_report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
