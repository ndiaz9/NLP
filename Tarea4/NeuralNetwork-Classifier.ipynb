{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import spacy\n",
    "import gensim\n",
    "import logging\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# remove warnings\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras import preprocessing\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(126646, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_character_text</th>\n",
       "      <th>spoken_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Miss Hoover</td>\n",
       "      <td>No, actually, it was a little of both. Sometim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lisa Simpson</td>\n",
       "      <td>Where's Mr. Bergstrom?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Miss Hoover</td>\n",
       "      <td>I don't know. Although I'd sure like to talk t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lisa Simpson</td>\n",
       "      <td>That life is worth living.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Edna Krabappel-Flanders</td>\n",
       "      <td>The polls will be open from now until the end ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        raw_character_text                                       spoken_words\n",
       "0              Miss Hoover  No, actually, it was a little of both. Sometim...\n",
       "1             Lisa Simpson                             Where's Mr. Bergstrom?\n",
       "2              Miss Hoover  I don't know. Although I'd sure like to talk t...\n",
       "3             Lisa Simpson                         That life is worth living.\n",
       "4  Edna Krabappel-Flanders  The polls will be open from now until the end ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# lectura de la data y eliminaci√≥n de registros repetidos y nulos\n",
    "documents = pd.read_csv('./datos/simpsons_dataset.csv').dropna().drop_duplicates()\n",
    "documents = documents.reset_index(drop=True)\n",
    "print(documents.shape)\n",
    "display(documents.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60610, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_character_text</th>\n",
       "      <th>spoken_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lisa Simpson</td>\n",
       "      <td>Where's Mr. Bergstrom?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lisa Simpson</td>\n",
       "      <td>That life is worth living.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Bart Simpson</td>\n",
       "      <td>Victory party under the slide!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Lisa Simpson</td>\n",
       "      <td>Mr. Bergstrom! Mr. Bergstrom!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Lisa Simpson</td>\n",
       "      <td>Do you know where I could find him?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   raw_character_text                         spoken_words\n",
       "1        Lisa Simpson               Where's Mr. Bergstrom?\n",
       "3        Lisa Simpson           That life is worth living.\n",
       "7        Bart Simpson       Victory party under the slide!\n",
       "8        Lisa Simpson        Mr. Bergstrom! Mr. Bergstrom!\n",
       "10       Lisa Simpson  Do you know where I could find him?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Filtrado por personajes principales\n",
    "main_characters =  [\"Lisa Simpson\", \"Bart Simpson\", \"Homer Simpson\", \"Marge Simpson\"]\n",
    "documents = documents[documents[\"raw_character_text\"].isin(main_characters)]\n",
    "print(documents.shape)\n",
    "display(documents.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sublist(list:list, n:int) -> list:\n",
    "    \"\"\"\n",
    "    Obtener sublistas de una lista\n",
    "    \"\"\"\n",
    "    return [list[i:i+n] for i in range(0, len(list), n)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vectors_characters(characters: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Extraer dialogos para todos los personajes en grupos de 5 oraciones\n",
    "    \"\"\"\n",
    "    sentences_big = get_sublist(characters['spoken_words'].tolist(),5)\n",
    "    df = pd.DataFrame({ 'spoken_words': sentences_big})\n",
    "    for index,dialogue in df['spoken_words'].items():\n",
    "        df.loc[index,\"spoken_words_concatenated\"] = ' '.join(dialogue)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents_dialogue_concatenated = documents.groupby(\"raw_character_text\")  \\\n",
    "                                    .apply(lambda x: get_vectors_characters(x)) \\\n",
    "                                    .reset_index(\"raw_character_text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_label(label:str) -> int:\n",
    "    \"\"\" \n",
    "    Categoriza los labels\n",
    "    \"\"\"\n",
    "    if label == \"bart simpson\":\n",
    "        return 1\n",
    "    elif label == \"lisa simpson\":\n",
    "        return 2\n",
    "    elif label == \"homer simpson\":\n",
    "        return 3\n",
    "    else : \n",
    "        return 4\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_character_text</th>\n",
       "      <th>spoken_words</th>\n",
       "      <th>spoken_words_concatenated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[Victory party under the slide!, Hey, thanks f...</td>\n",
       "      <td>victory party under the slide! hey, thanks for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[Somebody must have voted., Uh oh., I demand a...</td>\n",
       "      <td>somebody must have voted. uh oh. i demand a re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>[Ah, Dad, if just me, Milhouse and Lewis had v...</td>\n",
       "      <td>ah, dad, if just me, milhouse and lewis had vo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>[Please Dad., What?, Yes sir., They're fightin...</td>\n",
       "      <td>please dad. what? yes sir. they're fighting in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>[Dad, I have as much respect for you as I ever...</td>\n",
       "      <td>dad, i have as much respect for you as i ever ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   raw_character_text                                       spoken_words  \\\n",
       "0                   1  [Victory party under the slide!, Hey, thanks f...   \n",
       "1                   1  [Somebody must have voted., Uh oh., I demand a...   \n",
       "2                   1  [Ah, Dad, if just me, Milhouse and Lewis had v...   \n",
       "3                   1  [Please Dad., What?, Yes sir., They're fightin...   \n",
       "4                   1  [Dad, I have as much respect for you as I ever...   \n",
       "\n",
       "                           spoken_words_concatenated  \n",
       "0  victory party under the slide! hey, thanks for...  \n",
       "1  somebody must have voted. uh oh. i demand a re...  \n",
       "2  ah, dad, if just me, milhouse and lewis had vo...  \n",
       "3  please dad. what? yes sir. they're fighting in...  \n",
       "4  dad, i have as much respect for you as i ever ...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents_dialogue_concatenated[\"raw_character_text\"] = documents_dialogue_concatenated[\"raw_character_text\"].apply(lambda x: x.lower())\n",
    "documents_dialogue_concatenated[\"raw_character_text\"] = documents_dialogue_concatenated[\"raw_character_text\"].apply(convert_label)\n",
    "documents_dialogue_concatenated[\"spoken_words_concatenated\"] = documents_dialogue_concatenated[\"spoken_words_concatenated\"].apply(lambda x: x.lower())\n",
    "documents_dialogue_concatenated.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sentences = documents_dialogue_concatenated['spoken_words_concatenated'].values\n",
    "y = documents_dialogue_concatenated['raw_character_text'].values\n",
    "sentences_train, sentences_test, y_train, y_test = train_test_split(sentences, y, test_size=0.2, random_state=1)\n",
    "\n",
    "y_train_categorical = tf.one_hot(y_train,4)\n",
    "y_test_categorical = tf.one_hot(y_test,4)\n",
    "\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((sentences_train,y_train_categorical))\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((sentences_test,y_test_categorical))\n",
    "\n",
    "text_dataset = tf.data.Dataset.from_tensor_slices((sentences_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in the total set: 12123\n",
      "Number of rows of bart class: 0\n",
      "Number of rows of lisa class: 2414\n",
      "Number of rows of homer class: 2029\n",
      "Number of rows of marge class: 5195\n",
      "---------------------------------------------\n",
      "Number of rows in the training set: 9698\n",
      "Number of rows of bart class: 0\n",
      "Number of rows of lisa class: 1913\n",
      "Number of rows of homer class: 1598\n",
      "Number of rows of marge class: 4171\n",
      "---------------------------------------------\n",
      "Number of rows in the test set: 2425\n",
      "Number of rows of bart class: 0\n",
      "Number of rows of lisa class: 501\n",
      "Number of rows of homer class: 431\n",
      "Number of rows of marge class: 1024\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('Number of rows in the total set: {}'.format(sentences.shape[0]))\n",
    "print('Number of rows of bart class: {}'.format(y[y == 0].shape[0]))\n",
    "print('Number of rows of lisa class: {}'.format(y[y == 1].shape[0]))\n",
    "print('Number of rows of homer class: {}'.format(y[y == 2].shape[0]))\n",
    "print('Number of rows of marge class: {}'.format(y[y == 3].shape[0]))\n",
    "print('---------------------------------------------')\n",
    "\n",
    "print('Number of rows in the training set: {}'.format(sentences_train.shape[0]))\n",
    "print('Number of rows of bart class: {}'.format(y_train[y_train == 0].shape[0]))\n",
    "print('Number of rows of lisa class: {}'.format(y_train[y_train == 1].shape[0]))\n",
    "print('Number of rows of homer class: {}'.format(y_train[y_train == 2].shape[0]))\n",
    "print('Number of rows of marge class: {}'.format(y_train[y_train == 3].shape[0]))\n",
    "print('---------------------------------------------')\n",
    "\n",
    "print('Number of rows in the test set: {}'.format(sentences_test.shape[0]))\n",
    "\n",
    "print('Number of rows of bart class: {}'.format(y_test[y_test == 0].shape[0]))\n",
    "print('Number of rows of lisa class: {}'.format(y_test[y_test == 1].shape[0]))\n",
    "print('Number of rows of homer class: {}'.format(y_test[y_test == 2].shape[0]))\n",
    "print('Number of rows of marge class: {}'.format(y_test[y_test == 3].shape[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorize Layer Binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorize_layer_binary = TextVectorization(\n",
    "    ngrams=None, \n",
    "    max_tokens=200, vocabulary=None,\n",
    "    output_mode='binary', output_sequence_length=None, pad_to_max_tokens=True,\n",
    ")\n",
    "\n",
    "vectorize_layer_binary.adapt(text_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(vectorize_layer_binary.get_vocabulary())\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelsequ1 = Sequential()\n",
    "modelsequ1.add(vectorize_layer_binary)\n",
    "modelsequ1.add(layers.Embedding(vocab_size, embedding_dim, name=\"embedding\"))\n",
    "modelsequ1.add(layers.GlobalAveragePooling1D())\n",
    "modelsequ1.add(layers.Dense(50, activation='relu', name=\"Hidden_layer_2\"))\n",
    "modelsequ1.add(layers.Dense(4, activation='softmax', name=\"Output_layer\"))\n",
    "modelsequ1.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc', 'mse']) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "97/97 [==============================] - 3s 16ms/step - loss: 1.0135 - acc: 0.4211 - mse: 0.1511 - val_loss: 0.9472 - val_acc: 0.4223 - val_mse: 0.1443\n",
      "Epoch 2/10\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.8712 - acc: 0.4301 - mse: 0.1395 - val_loss: 0.8648 - val_acc: 0.4223 - val_mse: 0.1422\n",
      "Epoch 3/10\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.8197 - acc: 0.4301 - mse: 0.1390 - val_loss: 0.8389 - val_acc: 0.4223 - val_mse: 0.1422\n",
      "Epoch 4/10\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.8092 - acc: 0.4301 - mse: 0.1390 - val_loss: 0.8348 - val_acc: 0.4223 - val_mse: 0.1418\n",
      "Epoch 5/10\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.8071 - acc: 0.4301 - mse: 0.1391 - val_loss: 0.8346 - val_acc: 0.4223 - val_mse: 0.1413\n",
      "Epoch 6/10\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.8065 - acc: 0.4301 - mse: 0.1394 - val_loss: 0.8352 - val_acc: 0.4223 - val_mse: 0.1414\n",
      "Epoch 7/10\n",
      "97/97 [==============================] - 1s 10ms/step - loss: 0.8085 - acc: 0.4301 - mse: 0.1401 - val_loss: 0.8302 - val_acc: 0.4223 - val_mse: 0.1415\n",
      "Epoch 8/10\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.8092 - acc: 0.4227 - mse: 0.1405 - val_loss: 0.8311 - val_acc: 0.4223 - val_mse: 0.1431\n",
      "Epoch 9/10\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.8101 - acc: 0.4249 - mse: 0.1407 - val_loss: 0.8280 - val_acc: 0.4223 - val_mse: 0.1419\n",
      "Epoch 10/10\n",
      "97/97 [==============================] - 1s 11ms/step - loss: 0.8098 - acc: 0.4249 - mse: 0.1408 - val_loss: 0.8386 - val_acc: 0.4223 - val_mse: 0.1440\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b017680070>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 100\n",
    "epochs = 10\n",
    "\n",
    "# Fit the model using the train and test datasets.\n",
    "modelsequ1.fit(\n",
    "    train_dataset.batch(batch_size),\n",
    "    validation_data=test_dataset.batch(batch_size),\n",
    "    epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " text_vectorization (TextVec  (None, 200)              0         \n",
      " torization)                                                     \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 200, 10)           2000      \n",
      "                                                                 \n",
      " global_average_pooling1d (G  (None, 10)               0         \n",
      " lobalAveragePooling1D)                                          \n",
      "                                                                 \n",
      " Hidden_layer_2 (Dense)      (None, 50)                550       \n",
      "                                                                 \n",
      " Output_layer (Dense)        (None, 4)                 204       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,754\n",
      "Trainable params: 2,754\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelsequ1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76/76 [==============================] - 1s 4ms/step - loss: 0.8386 - acc: 0.4223 - mse: 0.1440\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8386245369911194, 0.4222680330276489, 0.14397282898426056]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelsequ1.evaluate(sentences_test,y_test_categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 1s 5ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       469\n",
      "           1       0.00      0.00      0.00       501\n",
      "           2       0.00      0.00      0.00       431\n",
      "           3       0.42      1.00      0.59      1024\n",
      "\n",
      "    accuracy                           0.42      2425\n",
      "   macro avg       0.11      0.25      0.15      2425\n",
      "weighted avg       0.18      0.42      0.25      2425\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\camilo\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\camilo\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\camilo\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "pred = modelsequ1.predict(sentences_test, batch_size=100, verbose=1) \n",
    "predicted = np.argmax(pred, axis=1)  \n",
    "report = classification_report(np.argmax(y_test_categorical, axis=1), predicted)  \n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorize Layer count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorize_layer_count = TextVectorization(\n",
    "    ngrams=None, \n",
    "    max_tokens=200, vocabulary=None,\n",
    "    output_mode='count', output_sequence_length=None, pad_to_max_tokens=True,\n",
    ")\n",
    "\n",
    "vectorize_layer_count.adapt(text_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_dim = 10\n",
    "vocab_size = len(vectorize_layer_count.get_vocabulary())\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelsequ2 = Sequential()\n",
    "modelsequ2.add(vectorize_layer_count)\n",
    "modelsequ2.add(layers.Embedding(vocab_size, embedding_dim, name=\"embedding\"))\n",
    "modelsequ2.add(layers.GlobalAveragePooling1D())\n",
    "modelsequ2.add(layers.Dense(100, activation='relu', name=\"Hidden_layer\"))\n",
    "modelsequ2.add(layers.Dense(4, activation='softmax', name=\"Output_layer\"))\n",
    "modelsequ2.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['acc', 'mse']) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "97/97 [==============================] - 5s 35ms/step - loss: 1.0301 - acc: 0.4301 - mse: 0.1531 - val_loss: 1.0035 - val_acc: 0.4223 - val_mse: 0.1493\n",
      "Epoch 2/10\n",
      "97/97 [==============================] - 3s 27ms/step - loss: 0.9474 - acc: 0.4301 - mse: 0.1436 - val_loss: 0.9475 - val_acc: 0.4223 - val_mse: 0.1439\n",
      "Epoch 3/10\n",
      "97/97 [==============================] - 3s 27ms/step - loss: 0.9038 - acc: 0.4301 - mse: 0.1399 - val_loss: 0.9180 - val_acc: 0.4223 - val_mse: 0.1422\n",
      "Epoch 4/10\n",
      "97/97 [==============================] - 3s 28ms/step - loss: 0.8800 - acc: 0.4301 - mse: 0.1388 - val_loss: 0.9000 - val_acc: 0.4223 - val_mse: 0.1416\n",
      "Epoch 5/10\n",
      "97/97 [==============================] - 3s 28ms/step - loss: 0.8649 - acc: 0.4301 - mse: 0.1384 - val_loss: 0.8875 - val_acc: 0.4223 - val_mse: 0.1413\n",
      "Epoch 6/10\n",
      "97/97 [==============================] - 3s 33ms/step - loss: 0.8542 - acc: 0.4301 - mse: 0.1382 - val_loss: 0.8779 - val_acc: 0.4223 - val_mse: 0.1412\n",
      "Epoch 7/10\n",
      "97/97 [==============================] - 3s 26ms/step - loss: 0.8459 - acc: 0.4301 - mse: 0.1381 - val_loss: 0.8702 - val_acc: 0.4223 - val_mse: 0.1411\n",
      "Epoch 8/10\n",
      "97/97 [==============================] - 2s 16ms/step - loss: 0.8392 - acc: 0.4301 - mse: 0.1380 - val_loss: 0.8640 - val_acc: 0.4223 - val_mse: 0.1410\n",
      "Epoch 9/10\n",
      "97/97 [==============================] - 3s 27ms/step - loss: 0.8341 - acc: 0.4301 - mse: 0.1380 - val_loss: 0.8592 - val_acc: 0.4223 - val_mse: 0.1410\n",
      "Epoch 10/10\n",
      "97/97 [==============================] - 2s 22ms/step - loss: 0.8302 - acc: 0.4301 - mse: 0.1381 - val_loss: 0.8557 - val_acc: 0.4223 - val_mse: 0.1410\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b017690070>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model using the train and test datasets.\n",
    "batch_size = 100\n",
    "epochs = 10\n",
    "\n",
    "modelsequ2.fit(\n",
    "    train_dataset.batch(batch_size),\n",
    "    validation_data=test_dataset.batch(batch_size),\n",
    "    epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " text_vectorization_1 (TextV  (None, 200)              0         \n",
      " ectorization)                                                   \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 200, 10)           2000      \n",
      "                                                                 \n",
      " global_average_pooling1d_1   (None, 10)               0         \n",
      " (GlobalAveragePooling1D)                                        \n",
      "                                                                 \n",
      " Hidden_layer (Dense)        (None, 100)               1100      \n",
      "                                                                 \n",
      " Output_layer (Dense)        (None, 4)                 404       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,504\n",
      "Trainable params: 3,504\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelsequ2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76/76 [==============================] - 0s 5ms/step - loss: 0.8557 - acc: 0.4223 - mse: 0.1410\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8557314276695251, 0.4222680330276489, 0.14097967743873596]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelsequ2.evaluate(sentences_test,y_test_categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 1s 6ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       469\n",
      "           1       0.00      0.00      0.00       501\n",
      "           2       0.00      0.00      0.00       431\n",
      "           3       0.42      1.00      0.59      1024\n",
      "\n",
      "    accuracy                           0.42      2425\n",
      "   macro avg       0.11      0.25      0.15      2425\n",
      "weighted avg       0.18      0.42      0.25      2425\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\camilo\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\camilo\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\camilo\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "pred = modelsequ2.predict(sentences_test, batch_size=100, verbose=1) \n",
    "predicted = np.argmax(pred, axis=1)  \n",
    "report = classification_report(np.argmax(y_test_categorical, axis=1), predicted)  \n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorize layer int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorize_layer_tfidf = TextVectorization(\n",
    "    ngrams=None, \n",
    "    max_tokens=200, vocabulary=None,\n",
    "    output_mode='int', output_sequence_length=None,\n",
    ")\n",
    "\n",
    "vectorize_layer_tfidf.adapt(text_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelsequ3 = Sequential()\n",
    "modelsequ3.add(vectorize_layer_tfidf)\n",
    "modelsequ3.add(layers.Embedding(vocab_size, embedding_dim, name=\"embedding\"))\n",
    "modelsequ3.add(layers.GlobalAveragePooling1D())\n",
    "modelsequ3.add(layers.Dense(50, activation='relu', name=\"Hidden_layer\"))\n",
    "modelsequ3.add(layers.Dense(4, activation='softmax', name=\"Output_layer\"))\n",
    "modelsequ3.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['acc', 'mse']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "97/97 [==============================] - 4s 32ms/step - loss: 1.0274 - acc: 0.4293 - mse: 0.1530 - val_loss: 0.9977 - val_acc: 0.4223 - val_mse: 0.1491\n",
      "Epoch 2/10\n",
      "97/97 [==============================] - 3s 29ms/step - loss: 0.9428 - acc: 0.4301 - mse: 0.1436 - val_loss: 0.9420 - val_acc: 0.4223 - val_mse: 0.1438\n",
      "Epoch 3/10\n",
      "97/97 [==============================] - 3s 27ms/step - loss: 0.9004 - acc: 0.4301 - mse: 0.1400 - val_loss: 0.9133 - val_acc: 0.4223 - val_mse: 0.1420\n",
      "Epoch 4/10\n",
      "97/97 [==============================] - 3s 28ms/step - loss: 0.8773 - acc: 0.4301 - mse: 0.1388 - val_loss: 0.8967 - val_acc: 0.4223 - val_mse: 0.1414\n",
      "Epoch 5/10\n",
      "97/97 [==============================] - 3s 27ms/step - loss: 0.8636 - acc: 0.4301 - mse: 0.1383 - val_loss: 0.8862 - val_acc: 0.4223 - val_mse: 0.1412\n",
      "Epoch 6/10\n",
      "97/97 [==============================] - 3s 33ms/step - loss: 0.8547 - acc: 0.4301 - mse: 0.1381 - val_loss: 0.8786 - val_acc: 0.4223 - val_mse: 0.1411\n",
      "Epoch 7/10\n",
      "97/97 [==============================] - 3s 28ms/step - loss: 0.8480 - acc: 0.4301 - mse: 0.1381 - val_loss: 0.8727 - val_acc: 0.4223 - val_mse: 0.1410\n",
      "Epoch 8/10\n",
      "97/97 [==============================] - 3s 30ms/step - loss: 0.8427 - acc: 0.4301 - mse: 0.1380 - val_loss: 0.8678 - val_acc: 0.4223 - val_mse: 0.1410\n",
      "Epoch 9/10\n",
      "97/97 [==============================] - 3s 31ms/step - loss: 0.8384 - acc: 0.4301 - mse: 0.1380 - val_loss: 0.8637 - val_acc: 0.4223 - val_mse: 0.1409\n",
      "Epoch 10/10\n",
      "97/97 [==============================] - 3s 29ms/step - loss: 0.8348 - acc: 0.4301 - mse: 0.1380 - val_loss: 0.8603 - val_acc: 0.4223 - val_mse: 0.1409\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b0188865b0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model using the train and test datasets.\n",
    "modelsequ3.fit(\n",
    "    train_dataset.batch(batch_size),\n",
    "    validation_data=test_dataset.batch(batch_size),\n",
    "    epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " text_vectorization_2 (TextV  (None, None)             0         \n",
      " ectorization)                                                   \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, None, 10)          2000      \n",
      "                                                                 \n",
      " global_average_pooling1d_2   (None, 10)               0         \n",
      " (GlobalAveragePooling1D)                                        \n",
      "                                                                 \n",
      " Hidden_layer (Dense)        (None, 50)                550       \n",
      "                                                                 \n",
      " Output_layer (Dense)        (None, 4)                 204       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,754\n",
      "Trainable params: 2,754\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "modelsequ3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76/76 [==============================] - 1s 3ms/step - loss: 0.8612 - acc: 0.4223 - mse: 0.1409\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8612480759620667, 0.4222680330276489, 0.14091575145721436]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelsequ3.evaluate(sentences_test,y_test_categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 0s 6ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       469\n",
      "           1       0.00      0.00      0.00       501\n",
      "           2       0.00      0.00      0.00       431\n",
      "           3       0.42      1.00      0.59      1024\n",
      "\n",
      "    accuracy                           0.42      2425\n",
      "   macro avg       0.11      0.25      0.15      2425\n",
      "weighted avg       0.18      0.42      0.25      2425\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\camilo\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\camilo\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\camilo\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "pred = modelsequ3.predict(sentences_test, batch_size=100, verbose=1) \n",
    "predicted = np.argmax(pred, axis=1)  \n",
    "report = classification_report(np.argmax(y_test_categorical, axis=1), predicted)  \n",
    "print(report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('nlp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "c7a79e9e75522a046d95171e373010a5dca4ce6e8605d007854b2218f1d88052"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
