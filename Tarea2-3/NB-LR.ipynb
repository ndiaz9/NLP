{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import xml.etree.ElementTree as ET\n",
    "import re\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "from gensim.parsing.porter import PorterStemmer \n",
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer,TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_documents(tmpdir,label,df):\n",
    "    for filename in sorted(os.listdir(tmpdir)):\n",
    "        with open(tmpdir+filename, encoding=\"utf8\", errors='ignore') as f:\n",
    "            lines = f.read()\n",
    "            df.loc[len(df)] = [label,lines]\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>documents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>From: mathew &lt;mathew@mantis.co.uk&gt;\\nSubject: A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>From: mathew &lt;mathew@mantis.co.uk&gt;\\nSubject: A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>From: I3150101@dbstu1.rz.tu-bs.de (Benedikt Ro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>From: mathew &lt;mathew@mantis.co.uk&gt;\\nSubject: R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>From: strom@Watson.Ibm.Com (Rob Strom)\\nSubjec...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                          documents\n",
       "0      0  From: mathew <mathew@mantis.co.uk>\\nSubject: A...\n",
       "1      0  From: mathew <mathew@mantis.co.uk>\\nSubject: A...\n",
       "2      0  From: I3150101@dbstu1.rz.tu-bs.de (Benedikt Ro...\n",
       "3      0  From: mathew <mathew@mantis.co.uk>\\nSubject: R...\n",
       "4      0  From: strom@Watson.Ibm.Com (Rob Strom)\\nSubjec..."
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate corpus for 20N\n",
    "path = 'Datasets/20news-18828/'\n",
    "labels = {}\n",
    "df = df = pd.DataFrame({\"label\": [], \"documents\": [] })\n",
    "def get_senteces_from_path_20N(path)->list:\n",
    "    for dirs in sorted(os.listdir(path)):\n",
    "        labels[dirs] = len(labels)\n",
    "        tmpdir = path+dirs+'/'\n",
    "        if not dirs.startswith('.'):\n",
    "            get_documents(tmpdir,labels[dirs],df)\n",
    "\n",
    "get_senteces_from_path_20N(path)\n",
    "df.head()     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(document: str) -> list:\n",
    "    \"\"\"\n",
    "    clean data by removing non-latin characters\n",
    "    stem data sentences\n",
    "    remove stop words from a document\n",
    "    \"\"\"\n",
    "    document = document.lower()\n",
    "    document = remove_stopwords(document)\n",
    "    document = re.sub('\\n', ' ', document)\n",
    "    document = re.sub('[^a-zA-Z]|[0-9]', ' ', document)\n",
    "    document = re.sub('\\s+', ' ', document)\n",
    "    p = PorterStemmer()\n",
    "    document = p.stem_sentence(document)\n",
    "    return document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>documents</th>\n",
       "      <th>documents_processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>From: mathew &lt;mathew@mantis.co.uk&gt;\\nSubject: A...</td>\n",
       "      <td>from mathew mathew manti co uk subject alt ath...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>From: mathew &lt;mathew@mantis.co.uk&gt;\\nSubject: A...</td>\n",
       "      <td>from mathew mathew manti co uk subject alt ath...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>From: I3150101@dbstu1.rz.tu-bs.de (Benedikt Ro...</td>\n",
       "      <td>from i dbstu rz tu bs de benedikt rosenau subj...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>From: mathew &lt;mathew@mantis.co.uk&gt;\\nSubject: R...</td>\n",
       "      <td>from mathew mathew manti co uk subject re univ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>From: strom@Watson.Ibm.Com (Rob Strom)\\nSubjec...</td>\n",
       "      <td>from strom watson ibm com rob strom subject re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18823</th>\n",
       "      <td>19</td>\n",
       "      <td>From: sbuckley@fraser.sfu.ca (Stephen Buckley)...</td>\n",
       "      <td>from sbucklei fraser sfu ca stephen bucklei su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18824</th>\n",
       "      <td>19</td>\n",
       "      <td>From: bakerj@gtephx.UUCP (Jon Baker)\\nSubject:...</td>\n",
       "      <td>from bakerj gtephx uucp jon baker subject re m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18825</th>\n",
       "      <td>19</td>\n",
       "      <td>From: pharvey@quack.kfu.com (Paul Harvey)\\nSub...</td>\n",
       "      <td>from pharvei quack kfu com paul harvei subject...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18826</th>\n",
       "      <td>19</td>\n",
       "      <td>From: &lt;KEVXU@CUNYVM.BITNET&gt;\\nSubject: Re: Info...</td>\n",
       "      <td>from kevxu cunyvm bitnet subject re info new a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18827</th>\n",
       "      <td>19</td>\n",
       "      <td>From: pharvey@quack.kfu.com (Paul Harvey)\\nSub...</td>\n",
       "      <td>from pharvei quack kfu com paul harvei subject...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18828 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                                          documents  \\\n",
       "0          0  From: mathew <mathew@mantis.co.uk>\\nSubject: A...   \n",
       "1          0  From: mathew <mathew@mantis.co.uk>\\nSubject: A...   \n",
       "2          0  From: I3150101@dbstu1.rz.tu-bs.de (Benedikt Ro...   \n",
       "3          0  From: mathew <mathew@mantis.co.uk>\\nSubject: R...   \n",
       "4          0  From: strom@Watson.Ibm.Com (Rob Strom)\\nSubjec...   \n",
       "...      ...                                                ...   \n",
       "18823     19  From: sbuckley@fraser.sfu.ca (Stephen Buckley)...   \n",
       "18824     19  From: bakerj@gtephx.UUCP (Jon Baker)\\nSubject:...   \n",
       "18825     19  From: pharvey@quack.kfu.com (Paul Harvey)\\nSub...   \n",
       "18826     19  From: <KEVXU@CUNYVM.BITNET>\\nSubject: Re: Info...   \n",
       "18827     19  From: pharvey@quack.kfu.com (Paul Harvey)\\nSub...   \n",
       "\n",
       "                                     documents_processed  \n",
       "0      from mathew mathew manti co uk subject alt ath...  \n",
       "1      from mathew mathew manti co uk subject alt ath...  \n",
       "2      from i dbstu rz tu bs de benedikt rosenau subj...  \n",
       "3      from mathew mathew manti co uk subject re univ...  \n",
       "4      from strom watson ibm com rob strom subject re...  \n",
       "...                                                  ...  \n",
       "18823  from sbucklei fraser sfu ca stephen bucklei su...  \n",
       "18824  from bakerj gtephx uucp jon baker subject re m...  \n",
       "18825  from pharvei quack kfu com paul harvei subject...  \n",
       "18826  from kevxu cunyvm bitnet subject re info new a...  \n",
       "18827  from pharvei quack kfu com paul harvei subject...  \n",
       "\n",
       "[18828 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['documents_processed'] = df.documents.apply(preprocessing)\n",
    "\n",
    "display(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in the total set: 18828\n",
      "Number of rows in the training set: 11294\n",
      "Number of rows in the validation set: 1885\n",
      "Number of rows in the test set: 5649\n"
     ]
    }
   ],
   "source": [
    "X_train_validation, X_test, y_train_validation, y_test = train_test_split(df['documents_processed'], \n",
    "                                                    df['label'], \n",
    "                                                    random_state=1,test_size=0.3)\n",
    "\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(X_train_validation, \n",
    "                                                    y_train_validation, \n",
    "                                                    random_state=1,test_size=0.143)\n",
    "\n",
    "print('Number of rows in the total set: {}'.format(df.shape[0]))\n",
    "print('Number of rows in the training set: {}'.format(X_train.shape[0]))\n",
    "print('Number of rows in the validation set: {}'.format(X_validation.shape[0]))\n",
    "print('Number of rows in the test set: {}'.format(X_test.shape[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vector = CountVectorizer()\n",
    "training_data_tf = count_vector.fit_transform(X_train)\n",
    "validation_data_tf = count_vector.transform(X_validation)\n",
    "testing_data_tf = count_vector.transform(X_test)\n",
    "\n",
    "training_validation_x_tf = np.concatenate((X_train,X_validation))\n",
    "cross_validation_x_tf = count_vector.transform(training_validation_x_tf)\n",
    "cross_validation_y_tf = np.concatenate((y_train,y_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_tf_norm = Normalizer().fit_transform(training_data_tf)\n",
    "validation_data_tf_norm = Normalizer().fit_transform(validation_data_tf)\n",
    "testing_data_tf_norm = Normalizer().fit_transform(testing_data_tf)\n",
    "cross_validation_data_tf_norm = Normalizer().fit_transform(cross_validation_x_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vector_tfidf = TfidfVectorizer()\n",
    "training_data_tfidf = count_vector_tfidf.fit_transform(X_train)\n",
    "validation_data_tfidf = count_vector_tfidf.transform(X_validation)\n",
    "testing_data_tfidf = count_vector_tfidf.transform(X_test)\n",
    "\n",
    "training_validation_x_tfidf = np.concatenate((X_train,X_validation))\n",
    "cross_validation_x_tfidf = count_vector.transform(training_validation_x_tfidf)\n",
    "cross_validation_y_tfidf = np.concatenate((y_train,y_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_tfidf_norm = Normalizer().fit_transform(training_data_tfidf) \n",
    "validation_data_tfidf_norm = Normalizer().fit_transform(validation_data_tfidf)\n",
    "testing_data_tfidf_norm = Normalizer().fit_transform(testing_data_tfidf)\n",
    "cross_validation_data_tfidf_norm = Normalizer().fit_transform(cross_validation_x_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.11566401, 0.09676361, 0.10223269, 0.11998487, 0.10903692,\n",
       "        0.10533309, 0.11847925, 0.10412741, 0.10813546, 0.09676623]),\n",
       " 'score_time': array([0.02333117, 0.01296496, 0.01705003, 0.01529741, 0.01595592,\n",
       "        0.01595926, 0.01563501, 0.01795244, 0.01568174, 0.01395631]),\n",
       " 'test_accuracy': array([0.83915023, 0.8262519 , 0.81335357, 0.83687405, 0.82245827,\n",
       "        0.83080425, 0.82549317, 0.83383915, 0.82397572, 0.81852696]),\n",
       " 'test_precision_macro': array([0.86546707, 0.86060998, 0.84402195, 0.85992666, 0.85951652,\n",
       "        0.86058952, 0.85894189, 0.85916675, 0.85461907, 0.84838882]),\n",
       " 'test_recall_macro': array([0.8215002 , 0.80866256, 0.79435201, 0.81977415, 0.80106467,\n",
       "        0.8093632 , 0.806046  , 0.81672769, 0.80640455, 0.80158858]),\n",
       " 'test_f1_macro': array([0.81738756, 0.80678346, 0.78902361, 0.81302181, 0.79173655,\n",
       "        0.80003935, 0.80011176, 0.80976988, 0.80305998, 0.79427992])}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naive_bayes = MultinomialNB()\n",
    "naive_bayes.fit(training_data_tf_norm,y_train)\n",
    "scores = cross_validate(naive_bayes, cross_validation_data_tf_norm, cross_validation_y_tf, cv=10, scoring=('accuracy','precision_macro','recall_macro','f1_macro'))\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Best Accuracy Through Grid Search : 0.8979108465263049\n",
      "best parameter :  {'alpha': 0.01}\n"
     ]
    }
   ],
   "source": [
    "params = {'alpha': [0.01, 0.1, 0.5, 1.0, 10.0, ],}\n",
    "\n",
    "multinomial_nb_grid = GridSearchCV(MultinomialNB(), param_grid=params, n_jobs=-1, cv=5, verbose=5)\n",
    "multinomial_nb_grid.fit(training_data_tf_norm,y_train)\n",
    "\n",
    "print(f'Best Accuracy Through Grid Search : {multinomial_nb_grid.best_score_}')\n",
    "print('best parameter : ', multinomial_nb_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.8148344839794653\n",
      "Precision score:  0.8497235627763603\n",
      "Recall score:  0.7992941108197578\n",
      "F1 score:  0.7893371741391044\n"
     ]
    }
   ],
   "source": [
    "predictions = naive_bayes.predict(testing_data_tf_norm)\n",
    "print('Accuracy score: ', format(accuracy_score(y_test, predictions)))\n",
    "print('Precision score: ', format(precision_score(y_test, predictions,average='macro')))\n",
    "print('Recall score: ', format(recall_score(y_test, predictions,average='macro')))\n",
    "print('F1 score: ', format(f1_score(y_test, predictions,average='macro')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.10323739, 0.11960053, 0.09362483, 0.16005301, 0.12537265,\n",
       "        0.09412718, 0.11175966, 0.14100099, 0.12577128, 0.13204122]),\n",
       " 'score_time': array([0.02035427, 0.        , 0.05270576, 0.01564074, 0.03124404,\n",
       "        0.0156188 , 0.01400661, 0.01562309, 0.01563025, 0.01562428]),\n",
       " 'test_accuracy': array([0.83915023, 0.8262519 , 0.81335357, 0.83687405, 0.82245827,\n",
       "        0.83080425, 0.82549317, 0.83383915, 0.82397572, 0.81852696]),\n",
       " 'test_precision_macro': array([0.86546707, 0.86060998, 0.84402195, 0.85992666, 0.85951652,\n",
       "        0.86058952, 0.85894189, 0.85916675, 0.85461907, 0.84838882]),\n",
       " 'test_recall_macro': array([0.8215002 , 0.80866256, 0.79435201, 0.81977415, 0.80106467,\n",
       "        0.8093632 , 0.806046  , 0.81672769, 0.80640455, 0.80158858]),\n",
       " 'test_f1_macro': array([0.81738756, 0.80678346, 0.78902361, 0.81302181, 0.79173655,\n",
       "        0.80003935, 0.80011176, 0.80976988, 0.80305998, 0.79427992])}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naive_bayes_2 = MultinomialNB()\n",
    "naive_bayes_2.fit(training_data_tfidf_norm,y_train)\n",
    "scores = cross_validate(naive_bayes, cross_validation_data_tfidf_norm, cross_validation_y_tfidf, cv=10, scoring=('accuracy','precision_macro','recall_macro','f1_macro'))\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Best Accuracy Through Grid Search : 0.8991506859090554\n",
      "best parameter :  {'alpha': 0.01}\n"
     ]
    }
   ],
   "source": [
    "params = {'alpha': [0.01, 0.1, 0.5, 1.0, 10.0, ],}\n",
    "\n",
    "multinomial_nb_grid = GridSearchCV(MultinomialNB(), param_grid=params, n_jobs=-1, cv=5, verbose=5)\n",
    "multinomial_nb_grid.fit(training_data_tfidf_norm,y_train)\n",
    "\n",
    "print(f'Best Accuracy Through Grid Search : {multinomial_nb_grid.best_score_}')\n",
    "print('best parameter : ', multinomial_nb_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.85519560984245\n",
      "Precision score:  0.874226295065692\n",
      "Recall score:  0.8429497747880884\n",
      "F1 score:  0.8378240079223621\n"
     ]
    }
   ],
   "source": [
    "predictions = naive_bayes_2.predict(testing_data_tfidf_norm)\n",
    "print('Accuracy score: ', format(accuracy_score(y_test, predictions)))\n",
    "print('Precision score: ', format(precision_score(y_test, predictions,average='macro')))\n",
    "print('Recall score: ', format(recall_score(y_test, predictions,average='macro')))\n",
    "print('F1 score: ', format(f1_score(y_test, predictions,average='macro')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regresion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\Documentos\\Semestre_2022-19\\Procesamiento_de_Lenguaje_Natural\\Tareas\\tareas\\repo\\Tarea2-3\\NB-LR.ipynb Cell 19'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Documentos/Semestre_2022-19/Procesamiento_de_Lenguaje_Natural/Tareas/tareas/repo/Tarea2-3/NB-LR.ipynb#ch0000016?line=0'>1</a>\u001b[0m clf_log \u001b[39m=\u001b[39m LogisticRegression(random_state\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m,multi_class\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mmultinomial\u001b[39;49m\u001b[39m'\u001b[39;49m)\u001b[39m.\u001b[39;49mfit(training_data_tf_norm, y_train)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Documentos/Semestre_2022-19/Procesamiento_de_Lenguaje_Natural/Tareas/tareas/repo/Tarea2-3/NB-LR.ipynb#ch0000016?line=1'>2</a>\u001b[0m scores \u001b[39m=\u001b[39m cross_validate(clf_log, cross_validation_data_tf_norm, cross_validation_y_tf, cv\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m, scoring\u001b[39m=\u001b[39m(\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mprecision_macro\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mrecall_macro\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mf1_macro\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Documentos/Semestre_2022-19/Procesamiento_de_Lenguaje_Natural/Tareas/tareas/repo/Tarea2-3/NB-LR.ipynb#ch0000016?line=2'>3</a>\u001b[0m scores\n",
      "File \u001b[1;32mc:\\Users\\camilo\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1406\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1404\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1405\u001b[0m     prefer \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mprocesses\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m-> 1406\u001b[0m fold_coefs_ \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs, verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[0;32m   1407\u001b[0m                        \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m_joblib_parallel_args(prefer\u001b[39m=\u001b[39;49mprefer))(\n\u001b[0;32m   1408\u001b[0m     path_func(X, y, pos_class\u001b[39m=\u001b[39;49mclass_, Cs\u001b[39m=\u001b[39;49m[C_],\n\u001b[0;32m   1409\u001b[0m               l1_ratio\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49ml1_ratio, fit_intercept\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit_intercept,\n\u001b[0;32m   1410\u001b[0m               tol\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtol, verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose, solver\u001b[39m=\u001b[39;49msolver,\n\u001b[0;32m   1411\u001b[0m               multi_class\u001b[39m=\u001b[39;49mmulti_class, max_iter\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_iter,\n\u001b[0;32m   1412\u001b[0m               class_weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclass_weight, check_input\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m   1413\u001b[0m               random_state\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrandom_state, coef\u001b[39m=\u001b[39;49mwarm_start_coef_,\n\u001b[0;32m   1414\u001b[0m               penalty\u001b[39m=\u001b[39;49mpenalty, max_squared_sum\u001b[39m=\u001b[39;49mmax_squared_sum,\n\u001b[0;32m   1415\u001b[0m               sample_weight\u001b[39m=\u001b[39;49msample_weight)\n\u001b[0;32m   1416\u001b[0m     \u001b[39mfor\u001b[39;49;00m class_, warm_start_coef_ \u001b[39min\u001b[39;49;00m \u001b[39mzip\u001b[39;49m(classes_, warm_start_coef))\n\u001b[0;32m   1418\u001b[0m fold_coefs_, _, n_iter_ \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mfold_coefs_)\n\u001b[0;32m   1419\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_iter_ \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(n_iter_, dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mint32)[:, \u001b[39m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\camilo\\anaconda3\\envs\\nlp\\lib\\site-packages\\joblib\\parallel.py:1043\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1034\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1035\u001b[0m     \u001b[39m# Only set self._iterating to True if at least a batch\u001b[39;00m\n\u001b[0;32m   1036\u001b[0m     \u001b[39m# was dispatched. In particular this covers the edge\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1040\u001b[0m     \u001b[39m# was very quick and its callback already dispatched all the\u001b[39;00m\n\u001b[0;32m   1041\u001b[0m     \u001b[39m# remaining jobs.\u001b[39;00m\n\u001b[0;32m   1042\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m-> 1043\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[0;32m   1044\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1046\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n",
      "File \u001b[1;32mc:\\Users\\camilo\\anaconda3\\envs\\nlp\\lib\\site-packages\\joblib\\parallel.py:861\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    859\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    860\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 861\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[0;32m    862\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\camilo\\anaconda3\\envs\\nlp\\lib\\site-packages\\joblib\\parallel.py:779\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    777\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    778\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[1;32m--> 779\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[0;32m    780\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    781\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    782\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    783\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    784\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32mc:\\Users\\camilo\\anaconda3\\envs\\nlp\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m     \u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[0;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32mc:\\Users\\camilo\\anaconda3\\envs\\nlp\\lib\\site-packages\\joblib\\_parallel_backends.py:572\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    569\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[0;32m    570\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    571\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 572\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[1;32mc:\\Users\\camilo\\anaconda3\\envs\\nlp\\lib\\site-packages\\joblib\\parallel.py:262\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    258\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    259\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    261\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 262\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    263\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\camilo\\anaconda3\\envs\\nlp\\lib\\site-packages\\joblib\\parallel.py:262\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    258\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    259\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    261\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 262\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    263\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\camilo\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\utils\\fixes.py:222\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    220\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    221\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig):\n\u001b[1;32m--> 222\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\camilo\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:758\u001b[0m, in \u001b[0;36m_logistic_regression_path\u001b[1;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight, l1_ratio)\u001b[0m\n\u001b[0;32m    755\u001b[0m \u001b[39mif\u001b[39;00m solver \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mlbfgs\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m    756\u001b[0m     iprint \u001b[39m=\u001b[39m [\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m50\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m100\u001b[39m, \u001b[39m101\u001b[39m][\n\u001b[0;32m    757\u001b[0m         np\u001b[39m.\u001b[39msearchsorted(np\u001b[39m.\u001b[39marray([\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m3\u001b[39m]), verbose)]\n\u001b[1;32m--> 758\u001b[0m     opt_res \u001b[39m=\u001b[39m optimize\u001b[39m.\u001b[39;49mminimize(\n\u001b[0;32m    759\u001b[0m         func, w0, method\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mL-BFGS-B\u001b[39;49m\u001b[39m\"\u001b[39;49m, jac\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m    760\u001b[0m         args\u001b[39m=\u001b[39;49m(X, target, \u001b[39m1.\u001b[39;49m \u001b[39m/\u001b[39;49m C, sample_weight),\n\u001b[0;32m    761\u001b[0m         options\u001b[39m=\u001b[39;49m{\u001b[39m\"\u001b[39;49m\u001b[39miprint\u001b[39;49m\u001b[39m\"\u001b[39;49m: iprint, \u001b[39m\"\u001b[39;49m\u001b[39mgtol\u001b[39;49m\u001b[39m\"\u001b[39;49m: tol, \u001b[39m\"\u001b[39;49m\u001b[39mmaxiter\u001b[39;49m\u001b[39m\"\u001b[39;49m: max_iter}\n\u001b[0;32m    762\u001b[0m     )\n\u001b[0;32m    763\u001b[0m     n_iter_i \u001b[39m=\u001b[39m _check_optimize_result(\n\u001b[0;32m    764\u001b[0m         solver, opt_res, max_iter,\n\u001b[0;32m    765\u001b[0m         extra_warning_msg\u001b[39m=\u001b[39m_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n\u001b[0;32m    766\u001b[0m     w0, loss \u001b[39m=\u001b[39m opt_res\u001b[39m.\u001b[39mx, opt_res\u001b[39m.\u001b[39mfun\n",
      "File \u001b[1;32mc:\\Users\\camilo\\anaconda3\\envs\\nlp\\lib\\site-packages\\scipy\\optimize\\_minimize.py:623\u001b[0m, in \u001b[0;36mminimize\u001b[1;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[0;32m    620\u001b[0m     \u001b[39mreturn\u001b[39;00m _minimize_newtoncg(fun, x0, args, jac, hess, hessp, callback,\n\u001b[0;32m    621\u001b[0m                               \u001b[39m*\u001b[39m\u001b[39m*\u001b[39moptions)\n\u001b[0;32m    622\u001b[0m \u001b[39melif\u001b[39;00m meth \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39ml-bfgs-b\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m--> 623\u001b[0m     \u001b[39mreturn\u001b[39;00m _minimize_lbfgsb(fun, x0, args, jac, bounds,\n\u001b[0;32m    624\u001b[0m                             callback\u001b[39m=\u001b[39mcallback, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39moptions)\n\u001b[0;32m    625\u001b[0m \u001b[39melif\u001b[39;00m meth \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mtnc\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m    626\u001b[0m     \u001b[39mreturn\u001b[39;00m _minimize_tnc(fun, x0, args, jac, bounds, callback\u001b[39m=\u001b[39mcallback,\n\u001b[0;32m    627\u001b[0m                          \u001b[39m*\u001b[39m\u001b[39m*\u001b[39moptions)\n",
      "File \u001b[1;32mc:\\Users\\camilo\\anaconda3\\envs\\nlp\\lib\\site-packages\\scipy\\optimize\\lbfgsb.py:360\u001b[0m, in \u001b[0;36m_minimize_lbfgsb\u001b[1;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[0;32m    354\u001b[0m task_str \u001b[39m=\u001b[39m task\u001b[39m.\u001b[39mtobytes()\n\u001b[0;32m    355\u001b[0m \u001b[39mif\u001b[39;00m task_str\u001b[39m.\u001b[39mstartswith(\u001b[39mb\u001b[39m\u001b[39m'\u001b[39m\u001b[39mFG\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m    356\u001b[0m     \u001b[39m# The minimization routine wants f and g at the current x.\u001b[39;00m\n\u001b[0;32m    357\u001b[0m     \u001b[39m# Note that interruptions due to maxfun are postponed\u001b[39;00m\n\u001b[0;32m    358\u001b[0m     \u001b[39m# until the completion of the current minimization iteration.\u001b[39;00m\n\u001b[0;32m    359\u001b[0m     \u001b[39m# Overwrite f and g:\u001b[39;00m\n\u001b[1;32m--> 360\u001b[0m     f, g \u001b[39m=\u001b[39m func_and_grad(x)\n\u001b[0;32m    361\u001b[0m \u001b[39melif\u001b[39;00m task_str\u001b[39m.\u001b[39mstartswith(\u001b[39mb\u001b[39m\u001b[39m'\u001b[39m\u001b[39mNEW_X\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m    362\u001b[0m     \u001b[39m# new iteration\u001b[39;00m\n\u001b[0;32m    363\u001b[0m     n_iterations \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\camilo\\anaconda3\\envs\\nlp\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:267\u001b[0m, in \u001b[0;36mScalarFunction.fun_and_grad\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    265\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m np\u001b[39m.\u001b[39marray_equal(x, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mx):\n\u001b[0;32m    266\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_x_impl(x)\n\u001b[1;32m--> 267\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_update_fun()\n\u001b[0;32m    268\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_grad()\n\u001b[0;32m    269\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mg\n",
      "File \u001b[1;32mc:\\Users\\camilo\\anaconda3\\envs\\nlp\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:233\u001b[0m, in \u001b[0;36mScalarFunction._update_fun\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    231\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_update_fun\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    232\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf_updated:\n\u001b[1;32m--> 233\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_update_fun_impl()\n\u001b[0;32m    234\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf_updated \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\camilo\\anaconda3\\envs\\nlp\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:137\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.update_fun\u001b[1;34m()\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mupdate_fun\u001b[39m():\n\u001b[1;32m--> 137\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf \u001b[39m=\u001b[39m fun_wrapped(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mx)\n",
      "File \u001b[1;32mc:\\Users\\camilo\\anaconda3\\envs\\nlp\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:134\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.fun_wrapped\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    130\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnfev \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    131\u001b[0m \u001b[39m# Send a copy because the user may overwrite it.\u001b[39;00m\n\u001b[0;32m    132\u001b[0m \u001b[39m# Overwriting results in undefined behaviour because\u001b[39;00m\n\u001b[0;32m    133\u001b[0m \u001b[39m# fun(self.x) will change self.x, with the two no longer linked.\u001b[39;00m\n\u001b[1;32m--> 134\u001b[0m \u001b[39mreturn\u001b[39;00m fun(np\u001b[39m.\u001b[39;49mcopy(x), \u001b[39m*\u001b[39;49margs)\n",
      "File \u001b[1;32mc:\\Users\\camilo\\anaconda3\\envs\\nlp\\lib\\site-packages\\scipy\\optimize\\optimize.py:74\u001b[0m, in \u001b[0;36mMemoizeJac.__call__\u001b[1;34m(self, x, *args)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, x, \u001b[39m*\u001b[39margs):\n\u001b[0;32m     73\u001b[0m     \u001b[39m\"\"\" returns the the function value \"\"\"\u001b[39;00m\n\u001b[1;32m---> 74\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_compute_if_needed(x, \u001b[39m*\u001b[39;49margs)\n\u001b[0;32m     75\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_value\n",
      "File \u001b[1;32mc:\\Users\\camilo\\anaconda3\\envs\\nlp\\lib\\site-packages\\scipy\\optimize\\optimize.py:68\u001b[0m, in \u001b[0;36mMemoizeJac._compute_if_needed\u001b[1;34m(self, x, *args)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m np\u001b[39m.\u001b[39mall(x \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mx) \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_value \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mjac \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     67\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mx \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(x)\u001b[39m.\u001b[39mcopy()\n\u001b[1;32m---> 68\u001b[0m     fg \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfun(x, \u001b[39m*\u001b[39;49margs)\n\u001b[0;32m     69\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mjac \u001b[39m=\u001b[39m fg[\u001b[39m1\u001b[39m]\n\u001b[0;32m     70\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_value \u001b[39m=\u001b[39m fg[\u001b[39m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\camilo\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:736\u001b[0m, in \u001b[0;36m_logistic_regression_path.<locals>.func\u001b[1;34m(x, *args)\u001b[0m\n\u001b[1;32m--> 736\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfunc\u001b[39m(x, \u001b[39m*\u001b[39margs): \u001b[39mreturn\u001b[39;00m _multinomial_loss_grad(x, \u001b[39m*\u001b[39;49margs)[\u001b[39m0\u001b[39m:\u001b[39m2\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\camilo\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:351\u001b[0m, in \u001b[0;36m_multinomial_loss_grad\u001b[1;34m(w, X, Y, alpha, sample_weight)\u001b[0m\n\u001b[0;32m    349\u001b[0m sample_weight \u001b[39m=\u001b[39m sample_weight[:, np\u001b[39m.\u001b[39mnewaxis]\n\u001b[0;32m    350\u001b[0m diff \u001b[39m=\u001b[39m sample_weight \u001b[39m*\u001b[39m (p \u001b[39m-\u001b[39m Y)\n\u001b[1;32m--> 351\u001b[0m grad[:, :n_features] \u001b[39m=\u001b[39m safe_sparse_dot(diff\u001b[39m.\u001b[39;49mT, X)\n\u001b[0;32m    352\u001b[0m grad[:, :n_features] \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m alpha \u001b[39m*\u001b[39m w\n\u001b[0;32m    353\u001b[0m \u001b[39mif\u001b[39;00m fit_intercept:\n",
      "File \u001b[1;32mc:\\Users\\camilo\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\utils\\validation.py:63\u001b[0m, in \u001b[0;36m_deprecate_positional_args.<locals>._inner_deprecate_positional_args.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m extra_args \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(args) \u001b[39m-\u001b[39m \u001b[39mlen\u001b[39m(all_args)\n\u001b[0;32m     62\u001b[0m \u001b[39mif\u001b[39;00m extra_args \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m---> 63\u001b[0m     \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[39m# extra_args > 0\u001b[39;00m\n\u001b[0;32m     66\u001b[0m args_msg \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m=\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(name, arg)\n\u001b[0;32m     67\u001b[0m             \u001b[39mfor\u001b[39;00m name, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(kwonly_args[:extra_args],\n\u001b[0;32m     68\u001b[0m                                  args[\u001b[39m-\u001b[39mextra_args:])]\n",
      "File \u001b[1;32mc:\\Users\\camilo\\anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\utils\\extmath.py:152\u001b[0m, in \u001b[0;36msafe_sparse_dot\u001b[1;34m(a, b, dense_output)\u001b[0m\n\u001b[0;32m    150\u001b[0m         ret \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mdot(a, b)\n\u001b[0;32m    151\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 152\u001b[0m     ret \u001b[39m=\u001b[39m a \u001b[39m@\u001b[39;49m b\n\u001b[0;32m    154\u001b[0m \u001b[39mif\u001b[39;00m (sparse\u001b[39m.\u001b[39missparse(a) \u001b[39mand\u001b[39;00m sparse\u001b[39m.\u001b[39missparse(b)\n\u001b[0;32m    155\u001b[0m         \u001b[39mand\u001b[39;00m dense_output \u001b[39mand\u001b[39;00m \u001b[39mhasattr\u001b[39m(ret, \u001b[39m\"\u001b[39m\u001b[39mtoarray\u001b[39m\u001b[39m\"\u001b[39m)):\n\u001b[0;32m    156\u001b[0m     \u001b[39mreturn\u001b[39;00m ret\u001b[39m.\u001b[39mtoarray()\n",
      "File \u001b[1;32mc:\\Users\\camilo\\anaconda3\\envs\\nlp\\lib\\site-packages\\scipy\\sparse\\base.py:566\u001b[0m, in \u001b[0;36mspmatrix.__rmatmul__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    563\u001b[0m \u001b[39mif\u001b[39;00m isscalarlike(other):\n\u001b[0;32m    564\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mScalar operands are not allowed, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    565\u001b[0m                      \u001b[39m\"\u001b[39m\u001b[39muse \u001b[39m\u001b[39m'\u001b[39m\u001b[39m*\u001b[39m\u001b[39m'\u001b[39m\u001b[39m instead\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 566\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__rmul__\u001b[39;49m(other)\n",
      "File \u001b[1;32mc:\\Users\\camilo\\anaconda3\\envs\\nlp\\lib\\site-packages\\scipy\\sparse\\base.py:550\u001b[0m, in \u001b[0;36mspmatrix.__rmul__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    548\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m:\n\u001b[0;32m    549\u001b[0m     tr \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(other)\u001b[39m.\u001b[39mtranspose()\n\u001b[1;32m--> 550\u001b[0m \u001b[39mreturn\u001b[39;00m (\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtranspose() \u001b[39m*\u001b[39;49m tr)\u001b[39m.\u001b[39mtranspose()\n",
      "File \u001b[1;32mc:\\Users\\camilo\\anaconda3\\envs\\nlp\\lib\\site-packages\\scipy\\sparse\\base.py:471\u001b[0m, in \u001b[0;36mspmatrix.__mul__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    469\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mul_vector(other\u001b[39m.\u001b[39mravel())\u001b[39m.\u001b[39mreshape(M, \u001b[39m1\u001b[39m)\n\u001b[0;32m    470\u001b[0m     \u001b[39melif\u001b[39;00m other\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m \u001b[39mand\u001b[39;00m other\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m] \u001b[39m==\u001b[39m N:\n\u001b[1;32m--> 471\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_mul_multivector(other)\n\u001b[0;32m    473\u001b[0m \u001b[39mif\u001b[39;00m isscalarlike(other):\n\u001b[0;32m    474\u001b[0m     \u001b[39m# scalar value\u001b[39;00m\n\u001b[0;32m    475\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mul_scalar(other)\n",
      "File \u001b[1;32mc:\\Users\\camilo\\anaconda3\\envs\\nlp\\lib\\site-packages\\scipy\\sparse\\compressed.py:491\u001b[0m, in \u001b[0;36m_cs_matrix._mul_multivector\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    489\u001b[0m \u001b[39m# csr_matvecs or csc_matvecs\u001b[39;00m\n\u001b[0;32m    490\u001b[0m fn \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(_sparsetools, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mformat \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m_matvecs\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m--> 491\u001b[0m fn(M, N, n_vecs, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindptr, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindices, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdata,\n\u001b[0;32m    492\u001b[0m    other\u001b[39m.\u001b[39;49mravel(), result\u001b[39m.\u001b[39;49mravel())\n\u001b[0;32m    494\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "clf_log = LogisticRegression(random_state=0,multi_class='multinomial').fit(training_data_tf_norm, y_train)\n",
    "scores = cross_validate(clf_log, cross_validation_data_tf_norm, cross_validation_y_tf, cv=10, scoring=('accuracy','precision_macro','recall_macro','f1_macro'))\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid={\"C\":np.logspace(-3,3,7), \"penalty\":[\"l1\",\"l2\"]}# l1 lasso l2 ridge\n",
    "logreg=LogisticRegression()\n",
    "logreg_cv=GridSearchCV(logreg,grid,cv=10)\n",
    "logreg_cv.fit(training_data_tf_norm,y_train)\n",
    "\n",
    "print(\"tuned hpyerparameters :(best parameters) \",logreg_cv.best_params_)\n",
    "print(\"accuracy :\",logreg_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.8773234200743495\n",
      "Precision score:  0.8781323314007391\n",
      "Recall score:  0.8753214903344413\n",
      "F1 score:  0.8763249880558377\n"
     ]
    }
   ],
   "source": [
    "predictions = clf_log.predict(testing_data_tf)\n",
    "print('Accuracy score: ', format(accuracy_score(y_test, predictions)))\n",
    "print('Precision score: ', format(precision_score(y_test, predictions,average='macro')))\n",
    "print('Recall score: ', format(recall_score(y_test, predictions,average='macro')))\n",
    "print('F1 score: ', format(f1_score(y_test, predictions,average='macro')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([58.21049595, 60.42855811, 56.58727145, 60.68442798, 63.94622207,\n",
       "        62.15066838, 57.19216442, 59.63363886, 61.07420874, 66.0457294 ]),\n",
       " 'score_time': array([0.03468251, 0.03705406, 0.02597952, 0.02541804, 0.0214572 ,\n",
       "        0.03434634, 0.0279274 , 0.02872157, 0.03333807, 0.03268409]),\n",
       " 'test_accuracy': array([0.86494689, 0.86342944, 0.85887709, 0.86191199, 0.85735964,\n",
       "        0.87177542, 0.85963581, 0.86646434, 0.84673748, 0.85649203]),\n",
       " 'test_precision_macro': array([0.87123872, 0.86500708, 0.86225159, 0.86523053, 0.85725527,\n",
       "        0.86981803, 0.86117677, 0.86845336, 0.84594393, 0.86026744]),\n",
       " 'test_recall_macro': array([0.85923957, 0.8593614 , 0.85321705, 0.85756171, 0.84756283,\n",
       "        0.86276777, 0.85359453, 0.86014987, 0.84047093, 0.84954364]),\n",
       " 'test_f1_macro': array([0.86171751, 0.86100895, 0.85525114, 0.85950587, 0.84916469,\n",
       "        0.86376013, 0.85525203, 0.86138409, 0.84125054, 0.8517437 ])}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_log_2 = LogisticRegression(random_state=0, max_iter=250, multi_class='multinomial').fit(training_data_tfidf_norm, y_train)\n",
    "scores = cross_validate(clf_log_2, cross_validation_data_tfidf_norm, cross_validation_y_tfidf, cv=10, scoring=('accuracy','precision_macro','recall_macro','f1_macro'))\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid={\"C\":np.logspace(-3,3,7), \"penalty\":[\"l1\",\"l2\"]}# l1 lasso l2 ridge\n",
    "logreg=LogisticRegression()\n",
    "logreg_cv=GridSearchCV(logreg,grid,cv=10)\n",
    "logreg_cv.fit(training_data_tfidf_norm,y_train)\n",
    "\n",
    "print(\"tuned hpyerparameters :(best parameters) \",logreg_cv.best_params_)\n",
    "print(\"accuracy :\",logreg_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.8413878562577447\n",
      "Precision score:  0.8511797899772114\n",
      "Recall score:  0.8382191237793639\n",
      "F1 score:  0.8374518856871092\n"
     ]
    }
   ],
   "source": [
    "predictions = clf_log_2.predict(testing_data_tf)\n",
    "print('Accuracy score: ', format(accuracy_score(test['label'].values, predictions)))\n",
    "print('Precision score: ', format(precision_score(test['label'].values, predictions,average='macro')))\n",
    "print('Recall score: ', format(recall_score(test['label'].values, predictions,average='macro')))\n",
    "print('F1 score: ', format(f1_score(test['label'].values, predictions,average='macro')))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('nlp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "c7a79e9e75522a046d95171e373010a5dca4ce6e8605d007854b2218f1d88052"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
